{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### Centroiding and correcting/filtering script for FLASH beamtime data #####################\n",
    "\n",
    "# Step 1: Centroiding the data. Loads raw .bin files with respective settings files, and centroids the data using Cython. Cluster\n",
    "#         data is examined via cluster-size and time-spread histograms. The centroided data is then saved to a list for further\n",
    "#         use (as a dataframe).\n",
    "\n",
    "# Step 2: Appending BAM, FEL pulse energies, BID, etc from h5 to the above centroided dataframes.\n",
    "\n",
    "# Step 3: For checking if BID assignment in each settings file is correct; plots number of ions in shot (ie, BID 'intensity')\n",
    "#         against pulse energy assigned to that shot. If a clear positive trend is seen, the settings files are good and don't \n",
    "#         need correcting. However, if no correlation is seen, the settings file needs to be corrected.\n",
    "\n",
    "# Step 4: Plotting FEL pulse intensity (in arbitrary units, but close to uJ) histogram. This then allows us to define a suitable \n",
    "#         FEL energy/intensity range to filter by when plotting ion-yields as a function of pump-probe delay time.\n",
    "\n",
    "# Step 5: Filtering BID-filtered data by FEL pulse intensity (filtering rows with FEL pulse intensities ~ 2 sigma away from mean\n",
    "#         FEL pulse intensity, found roughly in the centre of the histogram above).\n",
    "\n",
    "# Step 6: Plot time-of-flight spectra for each run on same plot; TOF calibration, and plotting in m/z domain to aid assignment.\n",
    "\n",
    "# Step 7: Normalising delay bins by number of shots in each bin. For each delay, we want to find how many unique tIds there are \n",
    "# and normalise by that amount. This produces fully corrected ion-yield plots - no more processing needs to be done.\n",
    "\n",
    "# Step 8: Saving filtered and processed data as .npy arrays\n",
    "\n",
    "# Step 9: Loading separate .npy files and concatenating them to make one large dataframe which can be saved.\n",
    "\n",
    "# Step 10: (Optional) Read in raw .bin files and settings files and make a concatenated uncentroided (but FEL-filtered) array\n",
    "#          to save.\n",
    "\n",
    "# (Cells labelled with 'JHM' correspond to code which I (James M) have either partially or fully developed or adapted. Code\n",
    "#  taken from other sources is credited cell-by-cell.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1a. Import modules and definitions for centroiding script.\n",
    "\n",
    "# Note: cython requires Visual Studio Community 2019, install the native development tools option under the Python\n",
    "# development workload (https://visualstudio.microsoft.com/).\n",
    "\n",
    "# Adapted from: Centroiding (PImMS binary) - 200911.ipynb (with JHM edits to read in BID and delay values from settings files)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "%load_ext cython\n",
    "\n",
    "# Creates PImMS x,y,t data from binary, sorts by t:\n",
    "def read_bin_torder(filename):\n",
    "    \n",
    "    #directory=os.chdir(r\"/asap3/flash/gpfs/bl1/2023/data/11013421/raw/PImMS/\")\n",
    "    directory=os.chdir(r'/asap3/flash/gpfs/bl1/2018/data/11003927/raw/pimms/') # 2018\n",
    "    file = open(str(filename)+'.bin', 'rb')\n",
    "    xyt_data = []\n",
    "\n",
    "    delays = 1000*((np.loadtxt(str(filename)+'-settings.txt', usecols=[3]))) # read in settings file and chooses delay value\n",
    "    delays = delays.astype(int)\n",
    "    BID = np.around(np.loadtxt(filename+'-settings.txt', usecols=[0]),3) # reads in BID values from settings file\n",
    "    BID = BID.astype(int)\n",
    "    \n",
    "    lasershot=0\n",
    "    \n",
    "    for block,d,b in zip(iter(lambda: file, ''),delays,BID):\n",
    "\n",
    "        try:\n",
    "            m, n = np.fromfile(file, dtype='<i', count=2)\n",
    "            frame = np.reshape(np.fromfile(file, dtype='<u2', count=m*n), (m, n))\n",
    "            lasershot += 1\n",
    "            if len(frame)>0:\n",
    "\n",
    "                ls_col = np.zeros((len(frame),1), dtype='int16')\n",
    "                ls_col = ls_col + lasershot\n",
    "                frame = np.append(frame,ls_col,1) # appends counter-generated tag IDs (starting from 0) to array\n",
    "\n",
    "                col_zeros = np.zeros((len(frame),1), dtype='int16')\n",
    "                col_tId = col_zeros + b\n",
    "                frame = np.append(frame,col_tId,axis=1) # appends settings file BIDs to array\n",
    "\n",
    "                col_zeros = np.zeros((len(frame),1), dtype='int16')\n",
    "                col_delays = col_zeros + d\n",
    "                frame = np.append(frame,col_delays,axis=1) # appends delay values to array\n",
    "                frame = frame[frame[:,2].argsort()] # orders by time-of-flight\n",
    "                xyt_data.append(frame)\n",
    "        except ValueError:\n",
    "            break\n",
    "    file.close()\n",
    "    return np.vstack(xyt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython --annotate\n",
    "# 1b. Creates centroiding function.\n",
    "\n",
    "# From: Centroiding (PImMS binary) - 200911.ipynb\n",
    "\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "cimport cython\n",
    "@cython.boundscheck(False)  # Deactivate bounds checking\n",
    "@cython.wraparound(False)   # Deactivate negative indexing\n",
    "@cython.cdivision(True)\n",
    "def centroid_shots2(int[:,:] input_arr, int time_win, int min_shot, int max_shot,\n",
    "                  int min_t, int max_t, int min_cluster_size, int max_cluster_size):\n",
    "    # Reads an input array of PImMS data (see program 3) and returns an [x, y, t, shot, cluster size, cluster timespread] \n",
    "    # array. Note that each frame must be ordered by time-of-flight.\n",
    " \n",
    "    # Define variables, data types, and empty arrays:\n",
    "    cdef int hit_no, p\n",
    "    cdef int i, j, min_time, max_time, size, shot, test, j_row2, j_col2\n",
    "    cdef int j_time, j_row, j_col, x, y, t, ct, i_row, i_col, k\n",
    "    cdef int nshots = 0\n",
    "    cdef int nevent = 0\n",
    "    cdef int nend = 0\n",
    "    cdef int t_spread = 0\n",
    "    cdef int cluster_min_time = 100000\n",
    "    cdef int cluster_max_time = 0\n",
    "    cdef int event_counter = 0    \n",
    "    cdef double row_sum, col_sum, time_sum, cx, cy, time                              \n",
    "    cdef np.ndarray[dtype=np.int32_t, ndim=2] im = np.zeros((324,324), dtype=np.int32) # Image array\n",
    "    cdef np.ndarray[dtype=np.int32_t, ndim=2] cluster_arr = np.zeros((5000,3), dtype=np.int32) # Cluster array\n",
    "    cdef np.ndarray[dtype=np.int32_t, ndim=2] event_array = np.zeros((50000000,6), dtype=np.int32) # Centroided events array\n",
    "    \n",
    "    # Determine hit count from input array rows:\n",
    "    hit_no = (input_arr.shape)[0] \n",
    "\n",
    "    # Cycle through frames, determine hits per frame:\n",
    "    for shot in range(min_shot, max_shot):\n",
    "        for test in range(nshots, hit_no):\n",
    "            if (input_arr[test,3] == shot):\n",
    "                nshots = test\n",
    "                break\n",
    "        for test in range(nshots, hit_no):\n",
    "            if input_arr[test,3] > shot:\n",
    "                nend = test-1\n",
    "                break\n",
    "\n",
    "        # Cycle through hits in a given frame, find unique pixel clusters in x,y,t:\n",
    "        for i in range(nshots, nend):\n",
    "            # Check if the hit has already been counted (1) or not (0):\n",
    "            if (input_arr[i,4] == 0): \n",
    "                t=input_arr[i,2]\n",
    "                # Check that the hit is within the desired time range, based on user input:\n",
    "                if min_t<=t<=max_t:\n",
    "                    if (input_arr[i,4] == 0):\n",
    "                        cluster_min_time = 100000\n",
    "                        cluster_max_time = 0\n",
    "                        size=1                       # Cluster size counter\n",
    "                        nevent+=1                    # Event counter\n",
    "                        input_arr[i,4]=1             # Count hit\n",
    "                        i_row = input_arr[i,0]\n",
    "                        i_col = input_arr[i,1]\n",
    "                        cluster_arr[size-1, 0] = i_row   # Add x to cluster array\n",
    "                        cluster_arr[size-1, 1] = i_col   # Add y to cluster array\n",
    "                        cluster_arr[size-1, 2] = t       # Add t to cluster array\n",
    "                        min_time = t                     # Establish initial cluster time \n",
    "                        max_time = t+time_win            # Establish allowed cluster time spread, based on user input \n",
    "                        im[i_row, i_col] = nevent        # Assign pixel coordinates to the event\n",
    "                        found_neighbour = True\n",
    "                        # Look for nearest neighbour pixels and add them to the cluster, continue while found_neighbour = True\n",
    "                        # or until the maximum cluster size (plus some leeway) is reached:\n",
    "                        for p in range(max_cluster_size+10):\n",
    "                            if found_neighbour:\n",
    "                                found_neighbour = False\n",
    "                                # Cycle through the hits in the frame again:\n",
    "                                for j in range(i, nend):\n",
    "                                    found_j = False\n",
    "                                    # Check that the new hit is also uncounted:\n",
    "                                    if input_arr[j,4]==0: \n",
    "                                        j_time = input_arr[j,2]\n",
    "                                        # Check that the new hit is also within the desired time range:\n",
    "                                        if min_time<=j_time<=max_time:\n",
    "                                            j_row = input_arr[j,0]\n",
    "                                            j_col = input_arr[j,1]\n",
    "                                            # Look for an event among the eight nearest neighbour pixels of the new hit,\n",
    "                                            # continue until found_j = True:\n",
    "                                            for j_row2 in range(j_row-1, j_row+2):\n",
    "                                                if found_j == False:\n",
    "                                                    for j_col2 in range(j_col-1, j_col+2):\n",
    "                                                        # If one of the neighbours is an assigned event, add the new hit to it:\n",
    "                                                        if im[j_row2, j_col2] == nevent:\n",
    "                                                            input_arr[j,4]=1                # Count new hit\n",
    "                                                            size+=1                         # Increase cluster size\n",
    "                                                            im[j_row, j_col] = nevent       # Assign pixel coordinates to event\n",
    "                                                            cluster_arr[size-1, 0] = j_row  # Add new x to cluster array\n",
    "                                                            cluster_arr[size-1, 1] = j_col  # Add new y to cluster array\n",
    "                                                            cluster_arr[size-1, 2] = j_time # Add new t to cluster array\n",
    "                                                            found_neighbour = True\n",
    "                                                            found_j = True\n",
    "                                                            break \n",
    "\n",
    "\n",
    "                        # Centroid cluster array into a single coordinate using a center-of-mass approach (see Slater, C. S. \n",
    "                        # Studies of photoinduced molecular dynamics using a fast imaging sensor; Springer, 2015; pp 54–62),\n",
    "                        # if the cluster size is within the set range:\n",
    "                        if min_cluster_size<=size<=max_cluster_size:\n",
    "                            row_sum = 0\n",
    "                            col_sum = 0\n",
    "                            time_sum = 0\n",
    "                            # Cycle through hits assigned to the cluster array, until the cluster size is reached.\n",
    "                            # NB. The cluster array is not reset to zero from cluster to cluster, but is overwritten,\n",
    "                            # data from larger clusters will exist in rows from 'size' onward, but won't be counted.\n",
    "                            for k in range(size):\n",
    "                                cx = cluster_arr[k, 0]\n",
    "                                cy = cluster_arr[k, 1]\n",
    "                                ct = cluster_arr[k, 2]\n",
    "                                time = ct-t+1           # Zero cluster event times to the earliest hit in the cluster.\n",
    "                                row_sum+=cx/time\n",
    "                                col_sum+=cy/time\n",
    "                                time_sum+=1/time\n",
    "                                \n",
    "                                # Determine earliest and latest times in the cluster, to calculate the time spread:                                \n",
    "                                if ct>cluster_max_time:\n",
    "                                    cluster_max_time = ct\n",
    "                                if ct<cluster_min_time:\n",
    "                                    cluster_min_time = ct\n",
    "                                    \n",
    "                                    \n",
    "                            t_spread = cluster_max_time - cluster_min_time\n",
    "                            \n",
    "                            # Add centroided event to array:\n",
    "                            event_array[event_counter, 0] = <int>(row_sum/time_sum+0.5)\n",
    "                            event_array[event_counter, 1] = <int>(col_sum/time_sum+0.5)\n",
    "                            event_array[event_counter, 2] = t\n",
    "                            event_array[event_counter, 3] = shot\n",
    "                            event_array[event_counter, 4] = size\n",
    "                            event_array[event_counter, 5] = t_spread\n",
    "                            event_counter+=1\n",
    "\n",
    "    return(event_array[0:event_counter,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1c. Centroids files (supplied as a list); returns an [x, y, t, shot, cluster size, cluster timespread] array.\n",
    "\n",
    "# Adapted from: Centroiding (PImMS binary) - 200911.ipynb (with JHM edits to loop over multiple run numbers and to save BID and\n",
    "#               delay values to separate lists for future reappending)\n",
    "\n",
    "import os\n",
    "\n",
    "#file_list=['222','223','224','226','227'] # indene 2023\n",
    "#file_list = ['147','148','150','151'] # fluorene 2023\n",
    "#file_list = ['108','109','110','111','112','113'] # CPP, 2023\n",
    "\n",
    "file_list = ['275','276','283','284','285','286','288','289','304']\n",
    "\n",
    "#file_list = ['129','130']\n",
    "\n",
    "read = 1\n",
    "counter = 1\n",
    "\n",
    "start_shots = 0 \n",
    "end_shots = 1000000\n",
    "\n",
    "min_time = 0 # minimum time-of-flight range\n",
    "max_time = 5000 # maximum time-of-flight range\n",
    "\n",
    "#min_time = 1831\n",
    "#max_time = 1840\n",
    "ion = 'total'\n",
    "\n",
    "# 2023 beamtime centroiding parameters\n",
    "timewin = 2 # for full data, approx. no clusters seen at time-windows greater than 6.\n",
    "min_cluster_size = 2 # statistically unlikely that two noisy pixels will activate next to each other in a given timeframe\n",
    "max_cluster_size = 10 # trade-off between size of data and not wanting to group lots of single pixel activations together\n",
    "\n",
    "event_array_list = []\n",
    "BID_delay_list_of_lists = []\n",
    "\n",
    "for f in file_list:\n",
    "    \n",
    "    # Read file, convert x,y,t data into input array:\n",
    "    if read:\n",
    "        start_time = time.time()\n",
    "        print('Opening file: '+str(f))\n",
    "        data_array = read_bin_torder(f)\n",
    "        print(\"Reading took %s seconds\" % round((time.time()-start_time),3))\n",
    "        #print(np.shape(data_array))\n",
    "    data_array = data_array[np.where((data_array[:,2]>=min_time) & (data_array[:,2]<=max_time))] # Filters data by time\n",
    "    \n",
    "    BID_delay_list = data_array[:,-3:] # extracts counter tag_id, BID, delay columns (in that order)\n",
    "    BID_delay_list_of_lists.append(BID_delay_list) # saving for reappending later (by file)\n",
    "    deleted_array = data_array[:, :-2] # data_array but without BID, delay\n",
    "    \n",
    "    data_array = deleted_array\n",
    "    print(f\"Shape of filtered data_array: {np.shape(data_array)}\")\n",
    "    \n",
    "    data_array2 = np.zeros((np.shape(data_array)[0], 6), dtype='int32') # Adds extra columns for hit counting. (changed to 7 instead of 6)\n",
    "#     data_array2.astype(int) \n",
    "    #print(np.shape(data_array2))\n",
    "    data_array2[:,:-2] = data_array # fills in data, returns data with two added columns of zeros\n",
    "    #print(data_array)\n",
    "    #print(data_array2.dtype)\n",
    "    #print(data_array[-1,-1]) # last BID\n",
    "\n",
    "    # Centroid data:\n",
    "    start_time = time.time()\n",
    "    print(f\"Starting centroiding for file: {f}\")\n",
    "    event_array = centroid_shots2(data_array2, timewin, start_shots, end_shots, min_time, max_time, min_cluster_size, max_cluster_size)\n",
    "    #print(np.shape(event_array))\n",
    "    event_array_list.append(event_array)\n",
    "    print(f\"Centroiding for file {f} took {round((time.time()-start_time),3)} seconds\")\n",
    "\n",
    "print(\"Centroiding calculations completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 1d. Examine cluster data. Plots cluster-size and time-spread histograms, and plots both together as a 2D histogram.\n",
    "\n",
    "# Adapted from: Centroiding (PImMS binary) - 200911.ipynb\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#directory=os.chdir(r\"/home/merrickj/Documents/indene_centroided\") # directory for saving centroided plots (indene)\n",
    "#directory=os.chdir(r\"/home/merrickj/Documents/fluorene_centroided\") # directory for saving centroided plots (fluorene)\n",
    "#directory=os.chdir(r\"/home/merrickj/Documents/CPP_centroided\") # directory for saving centroided plots (CPP)\n",
    "\n",
    "directory = os.chdir(r\"/home/merrickj/Documents/fluorene_2018_all\")\n",
    "\n",
    "for f, event_array in zip(file_list, event_array_list):\n",
    "    \n",
    "    # Cluster size histogram:\n",
    "    unique, counts = np.unique(event_array[:,4], return_counts=True)\n",
    "    fig, ax = plt.subplots(figsize=(9,5))\n",
    "    ax.bar(unique, counts, alpha=0.5)\n",
    "    ax.set_xlim(min_cluster_size, max_cluster_size)\n",
    "    ax.set_title(f\"Cluster-size histogram: ({min_time},{max_time})\", fontsize=16, y=1.03, pad = 10)\n",
    "    ax.set_xlabel('Cluster size / pixels', fontsize=12)\n",
    "    ax.set_ylabel('Counts', fontsize=12)\n",
    "    ax.tick_params(axis='x', labelsize=12)\n",
    "    ax.tick_params(axis='y', labelsize=12)\n",
    "    ax.grid(which='major')\n",
    "    ax.grid(which='minor')\n",
    "    ax.minorticks_on()\n",
    "    \n",
    "    textstr = '\\n'.join((f\"File: {f}\",f\"Min. cluster size / pixels: {min_cluster_size}\",f\"Max. cluster size / pixels: {max_cluster_size}\", f\"Max. time spread / timebins: {timewin}\"))\n",
    "    props = dict(boxstyle='round', facecolor='white', alpha=0.5)\n",
    "    ax.text(1.05, 0.50, textstr, transform=ax.transAxes, fontsize=14,\n",
    "    verticalalignment='center', bbox=props)\n",
    "    \n",
    "    #fig.savefig(f\"run_{f}_centroided_clustersize_histogram_{ion}.png\",bbox_inches=\"tight\")\n",
    "\n",
    "    # Time spread histogram:\n",
    "    unique2, counts2 = np.unique(event_array[:,5], return_counts=True)\n",
    "    fig2, ax2 = plt.subplots(figsize=(9,5))\n",
    "    ax2.bar(unique2, counts2, alpha=0.5)\n",
    "    ax2.set_xlim(0,timewin)\n",
    "    ax2.set_title(f\"Time-spread histogram: ({min_time},{max_time})\", fontsize=16, y=1.03, pad = 10)\n",
    "    ax2.set_xlabel('Time-bins', fontsize=12)\n",
    "    ax2.set_ylabel('Counts', fontsize=12)\n",
    "    ax2.tick_params(axis='x', labelsize=12)\n",
    "    ax2.tick_params(axis='y', labelsize=12)\n",
    "    ax2.grid(which='major')\n",
    "    ax2.grid(which='minor')\n",
    "    ax2.minorticks_on()\n",
    "    \n",
    "    textstr = '\\n'.join((f\"File: {f}\",f\"Min. cluster size / pixels: {min_cluster_size}\",f\"Max. cluster size / pixels: {max_cluster_size}\", f\"Max. time spread / timebins: {timewin}\"))\n",
    "    props = dict(boxstyle='round', facecolor='white', alpha=0.5)\n",
    "    ax2.text(1.05, 0.50, textstr, transform=ax2.transAxes, fontsize=14,\n",
    "    verticalalignment='center', bbox=props)\n",
    "    \n",
    "    #fig2.savefig(f\"run_{f}_centroided_timebinsize_histogram_{ion}.png\",bbox_inches=\"tight\")\n",
    "\n",
    "    # 2D distribution:\n",
    "    cluster_dist, xedges, yedges = np.histogram2d(event_array[:,4], event_array[:,5], bins =[np.arange(0,61), np.arange(0,9)])\n",
    "    fig3,ax3 = plt.subplots(figsize=(9,5))\n",
    "    picture = ax3.imshow(cluster_dist, interpolation='nearest', aspect='auto', cmap='inferno', vmax=np.max(cluster_dist))\n",
    "    ax3.set_title(f\"Cluster-size / time-spread histogram: ({min_time},{max_time})\", fontsize=16, y=1.03, pad = 10)\n",
    "    ax3.set_xlabel('Time-bin', fontsize=12)\n",
    "    ax3.set_ylabel('Cluster size / pixels', fontsize=12)\n",
    "    ax3.tick_params(axis='x', labelsize=12)\n",
    "    ax3.tick_params(axis='y', labelsize=12)\n",
    "    ax3.set_xlim(0,7)\n",
    "    ax3.set_ylim(min_cluster_size,max_cluster_size)\n",
    "    ax3.grid(which='major')\n",
    "    ax3.grid(which='minor')\n",
    "    cbar = plt.colorbar(picture)\n",
    "    cbar.set_label('Intensity / counts ', fontsize = 14)\n",
    "    \n",
    "    textstr = '\\n'.join((f\"File: {f}\",f\"Min. cluster size / pixels: {min_cluster_size}\",f\"Max. cluster size / pixels: {max_cluster_size}\", f\"Max. time spread / timebins: {timewin}\"))\n",
    "    props = dict(boxstyle='round', facecolor='white', alpha=0.5)\n",
    "    ax3.text(1.30, 0.50, textstr, transform=ax3.transAxes, fontsize=14,\n",
    "    verticalalignment='center', bbox=props)\n",
    "    \n",
    "    #fig3.savefig(f\"run_{f}_centroided_clustersize_timebinsize_2dhistogram_{ion}.png\",bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1e. Making a list of centroided dataframes\n",
    "\n",
    "centroided_df_list = []\n",
    "\n",
    "for f, event_array, BID_delay_list in zip(file_list, event_array_list, BID_delay_list_of_lists):\n",
    "    \n",
    "    print(f\"File: {f}\")\n",
    "    \n",
    "    df = pd.DataFrame(event_array, columns = ['x','y','ToF','counter_tagID','size','spread'])\n",
    "    \n",
    "    df_to_append = pd.DataFrame(BID_delay_list, columns = ['counter_tagID', 'BID', 'delay'])\n",
    "    df_to_append = df_to_append.drop_duplicates()\n",
    "    \n",
    "    total_df = df.merge(df_to_append, on = 'counter_tagID') # reappends BID and delay to data\n",
    "    total_df = total_df.drop(['counter_tagID'], axis = 1) # counter_tagID isn't needed after centroiding\n",
    "    total_df = total_df.reindex(columns=['x','y','ToF','BID','delay','size','spread']) # reorders columns as wanted\n",
    "    \n",
    "    centroided_df_list.append(total_df)\n",
    "    print(total_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 2. Appending BAM, FEL pulse energies, BID, etc from h5 to the above dataframes. (JU + JHM)\n",
    "\n",
    "import h5py\n",
    "import gc\n",
    "import os\n",
    "import glob\n",
    "\n",
    "#file_list=['222','223','224','226','227'] # run numbers for indene 2023\n",
    "#hdf_file_list=['44345','44346','44347','44348','44349'] # corresponding h5 run numbers for indene 2023\n",
    "\n",
    "# file_list = ['147','148','150','151'] # fluorene 2023\n",
    "# hdf_file_list = ['44249','44250','44251','44252'] # fluorene 2023\n",
    "\n",
    "#file_list = ['129','130'] # CPP 2023\n",
    "#hdf_file_list = ['44227','44228'] # CPP 2023\n",
    "\n",
    "file_list = ['284'] # fluorene 2018\n",
    "hdf_file_list = ['21608'] # fluorene 2018\n",
    "\n",
    "BID_filtered_df_list= []\n",
    "#os.chdir(r\"/asap3/flash/gpfs/bl1/2023/data/11013421/raw/hdf/express-0/fl1user1/\") # 2023\n",
    "os.chdir(r\"/asap3/flash/gpfs/bl1/2018/data/11003927/raw/hdf/online-2/fl1user1/\") # 2018\n",
    "h5_file_list = os.listdir() # lists ALL h5 files in this directory (for entire beamtime)\n",
    "\n",
    "for run_number, hdf_file in enumerate(hdf_file_list): # loop over run numbers\n",
    "    \n",
    "    print(f\"Run number: {file_list[run_number]}\")\n",
    "    print(f\"Length of df list: {len(centroided_df_list)}\")\n",
    "    print(f\"Length of file list: {len(file_list)}\")\n",
    "    \n",
    "    data_energy = []\n",
    "    data_BAM = []\n",
    "    counter_hdf = 1\n",
    "    \n",
    "    for file in h5_file_list: # looping over all h5 files in directory\n",
    "        \n",
    "        if f\"run{hdf_file}\" in str(file): # filtering h5 files by run number\n",
    "            \n",
    "            with h5py.File(file, 'r') as hdf:\n",
    "                \n",
    "                #energy = np.array(hdf.get('FL1/Photon Diagnostic/GMD/Pulse resolved energy/energy BDA/value')) # 2023\n",
    "                energy = np.array(hdf.get('Photon Diagnostic/GMD/Pulse resolved energy/energy BDA (raw) copy')) # 2018\n",
    "                #print(energy)\n",
    "\n",
    "                #energy_BIDs = hdf.get('FL1/Photon Diagnostic/GMD/Pulse resolved energy/energy BDA/index')[()] # 2023\n",
    "                energy_BIDs = hdf.get('Photon Diagnostic/GMD/Pulse resolved energy/energy BDA (raw) copy') # 2018\n",
    "                print(energy_BIDs)\n",
    "                \n",
    "                #BAM = hdf.get('FL1/Electron Diagnostic/Bunch charge/before undulator/value') # 2023\n",
    "                BAM = hdf.get('Electron Diagnostic/BAM/4DBC3/electron bunch arrival time (low charge)').value # 2018\n",
    "                print(BAM)\n",
    "                \n",
    "                #BAM_BIDs = hdf.get('FL1/Electron Diagnostic/Bunch charge/before undulator/index') # 2023\n",
    "                BAM_BIDs = hdf.get('FL1/Electron Diagnostic/BAM/1SFELC/electron bunch arrival time (low charge)/index').value\n",
    "\n",
    "                for x in np.arange(len(energy)):\n",
    "                    test = np.zeros(2)\n",
    "                    test[0] = energy[x][0][0]\n",
    "                    test[1] = energy_BIDs[x]\n",
    "                    data_energy.append(test)\n",
    "                for y in np.arange(len(BAM)):\n",
    "                    BAM_values = np.zeros(2)\n",
    "                    BAM_values[0] = BAM[y][0]\n",
    "                    BAM_values[1] = BAM_BIDs[y]\n",
    "                    data_BAM.append(BAM_values)\n",
    "                hdf.close()\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    #print(f\"data_energy:{data_energy}\")\n",
    "    data_energy=np.vstack(data_energy)\n",
    "    data_energy = data_energy[data_energy[:,1].argsort()]\n",
    "    data_BAM=np.vstack(data_BAM)\n",
    "    data_BAM = data_BAM[data_BAM[:,1].argsort()]\n",
    "    gc.collect()\n",
    "\n",
    "    df = centroided_df_list[run_number]\n",
    "    #print(df)\n",
    "    df_energy = pd.DataFrame(data_energy,columns =['Energy','BID'])\n",
    "    df_BAM = pd.DataFrame(data_BAM,columns =['BAM','BID'])\n",
    "    #print(df_energy)\n",
    "    #print(df_BAM)\n",
    "    \n",
    "    BID_filtered_df = df_energy.merge(df_BAM,on = 'BID').merge(df,on = 'BID')\n",
    "    #BID_filtered_df = pd.merge(data,df,on = \"BID\")\n",
    "    BID_filtered_df['delay'] = BID_filtered_df['delay'].apply(lambda x: x*0.001) # just converts delay to picoseconds (ps)\n",
    "    BID_filtered_df['Jitter_delay'] = BID_filtered_df['delay'] - BID_filtered_df['BAM']\n",
    "    #BID_filtered_df['Delay_round'] = BID_filtered_df.Jitter_delay.mul(2).round(1).div(2) # rounds BAM-corrected delay to nearest 0.05 ps (as given by delay step size in logbook) - indene, fluorene\n",
    "    BID_filtered_df['Delay_round'] = BID_filtered_df.Jitter_delay.mul(2).round(1).div(1) # round to nearest 0.1 (for CPP)\n",
    "    print(np.unique(BID_filtered_df['Delay_round']))\n",
    "    #print(BID_filtered_df)\n",
    "\n",
    "    # Getting rid of columns which aren't needed\n",
    "\n",
    "    del BID_filtered_df['BAM']\n",
    "    del BID_filtered_df['delay']\n",
    "    del BID_filtered_df['Jitter_delay']\n",
    "    #del BID_filtered_df['size']\n",
    "    #del BID_filtered_df['spread']\n",
    "\n",
    "    print(BID_filtered_df)\n",
    "    BID_filtered_df_list.append(BID_filtered_df)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 3. (For checking if BID assignment in each settings file is correct): Plotting number of ions in shot (ie, BID 'intensity')\n",
    "#    against pulse energy assigned to that shot. If a clear positive trend is seen, the settings files are good and don't need\n",
    "#    correcting. However, if no correlation is seen, the settings file needs to be corrected (see below - eventually). (JHM)\n",
    "\n",
    "# N.B: Now scatter plots as intensity heatmaps instead.\n",
    "\n",
    "directory=os.chdir(r\"/home/merrickj/Documents/indene_BID_filter_check_plots\")\n",
    "#directory=os.chdir(r\"/home/merrickj/Documents/fluorene_BID_filter_check_plots\")\n",
    "#directory=os.chdir(r\"/home/merrickj/Documents/CPP_BID_filter_check_plots\")\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "for df,file in zip(BID_filtered_df_list,file_list):\n",
    "    \n",
    "    ions_in_shot_df = df.groupby(['BID'], sort=False).size().reset_index(name='ions_in_shot') # produces dataframe containing BID against ion count; preserves order of BIDs\n",
    "    ions_in_shot_list = ions_in_shot_df['ions_in_shot'].to_list()\n",
    "    BID_list = ions_in_shot_df['BID'].to_list()\n",
    "    print(f\"Length of ions_in_shot_list list: {len(ions_in_shot_list)}\")\n",
    "    \n",
    "    FEL_pulse_energy_per_shot = []\n",
    "    \n",
    "    for BID in BID_list:\n",
    "        \n",
    "        locating_df = df.loc[df['BID'] == BID, 'Energy'].iloc[0]\n",
    "        FEL_pulse_energy_per_shot.append(locating_df)\n",
    "        \n",
    "    print(f\"Length of FEL_pulse_energy_per_shot list: {len(FEL_pulse_energy_per_shot)}\")\n",
    "    \n",
    "    ions_in_shot_list_copy = ions_in_shot_list # saves copies for loop iterations below\n",
    "    FEL_pulse_energy_per_shot_copy = FEL_pulse_energy_per_shot\n",
    "    \n",
    "    # Plotting code #\n",
    "    fig, (ax1,ax2,ax3) = plt.subplots(nrows = 1, ncols = 3, figsize = (18,8), sharey = True)\n",
    "    \n",
    "    ax1.set_xlabel('FEL pulse energy / a.u.', fontsize=14)\n",
    "    ax2.set_xlabel('FEL pulse energy / a.u.', fontsize=14)\n",
    "    ax3.set_xlabel('FEL pulse energy / a.u.', fontsize=14)\n",
    "    plt.tick_params(axis='x', labelsize=12)\n",
    "    ax1.set_ylabel('Ions in shot', fontsize=14)\n",
    "    plt.tick_params(axis='y', labelsize=12)\n",
    "    \n",
    "    ax1.grid(which='major')\n",
    "    ax1.grid(which='minor')\n",
    "    ax1.minorticks_on()\n",
    "    ax2.grid(which='major')\n",
    "    ax2.grid(which='minor')\n",
    "    ax2.minorticks_on()\n",
    "    ax3.grid(which='major')\n",
    "    ax3.grid(which='minor')\n",
    "    ax3.minorticks_on()\n",
    "    \n",
    "    \n",
    "    plt.suptitle(f\"Ions in shot versus FEL pulse energy for file: {file}\", fontsize = 16) # title at top of graph\n",
    "    \n",
    "    BID_shift_list = [-1,0,1] # BID shifts list for subplot\n",
    "    \n",
    "    for BID_shift in BID_shift_list:\n",
    "        \n",
    "        ions_in_shot_list = ions_in_shot_list_copy # resets list for second and third loop iterations\n",
    "        FEL_pulse_energy_per_shot= FEL_pulse_energy_per_shot_copy # resets list for second and third loop iterations\n",
    "        \n",
    "        if BID_shift == -1:\n",
    "\n",
    "            # for shifting BID by -1; deletes first entry in ions_in_shot_list and last entry in FEL_pulse_energy_per_shot list\n",
    "            h1 = ax1.hist2d(ions_in_shot_list[1:], FEL_pulse_energy_per_shot[:-1], bins=(100, 100), cmap=plt.cm.Blues)\n",
    "            \n",
    "        elif BID_shift  == 0:\n",
    "            \n",
    "            # no BID shift, so no need to splice\n",
    "            h2 = ax2.hist2d(ions_in_shot_list, FEL_pulse_energy_per_shot, bins=(100, 100), cmap=plt.cm.Blues)\n",
    "        \n",
    "        elif BID_shift == 1:\n",
    "\n",
    "            # for shifting BID by +1; delete last entry in ions_in_shot_list and first entry in FEL_pulse_energy_per_shot list\n",
    "            h3 = ax3.hist2d(ions_in_shot_list[:-1], FEL_pulse_energy_per_shot[1:], bins=(100, 100), cmap=plt.cm.Blues)\n",
    "        \n",
    "    fig.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=0.15)\n",
    "    \n",
    "    ax1.set_title(f\" BID shift = {BID_shift_list[0]}\", fontsize = 14, loc = 'left')\n",
    "    ax2.set_title(f\" BID shift = {BID_shift_list[1]}\", fontsize = 14, loc = 'left')\n",
    "    ax3.set_title(f\" BID shift = +{BID_shift_list[2]}\", fontsize = 14, loc = 'left')\n",
    "    \n",
    "    cbar1 = plt.colorbar(h1[3], ax = ax1, orientation = 'horizontal')\n",
    "    cbar1.set_label('Intensity / counts ', fontsize = 14)\n",
    "    cbar2 = plt.colorbar(h2[3], ax = ax2, orientation = 'horizontal')\n",
    "    cbar2.set_label('Intensity / counts ', fontsize = 14)\n",
    "    cbar3 = plt.colorbar(h3[3], ax = ax3, orientation = 'horizontal')\n",
    "    cbar3.set_label('Intensity / counts ', fontsize = 14)\n",
    "    \n",
    "    fig.savefig(f\"run_{file}_2Dhistogram_BIDshifts.png\",bbox_inches=\"tight\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 4. Plotting FEL pulse intensity (in arbitrary units, but close to uJ) histogram. This then allows us to define a suitable FEL\n",
    "#    energy/intensity range to filter by when plotting ion-yields as a function of pump-probe delay time. (JHM)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mu_list = []\n",
    "std_list = []\n",
    "FEL_lower_list = []\n",
    "FEL_higher_list = []\n",
    "\n",
    "for run_number, BID_filtered_df in enumerate(BID_filtered_df_list): # just looping over every BID-filtered dataframe in list\n",
    "    \n",
    "    energies = np.array(BID_filtered_df['Energy'])\n",
    "    fig, ax = plt.subplots(figsize = (10,8))\n",
    "    ax.hist(energies, bins = 100)\n",
    "    ax.grid(which='major')\n",
    "    ax.grid(which='minor')\n",
    "    ax.minorticks_on()\n",
    "    plt.xlabel('FEL pulse intensity / a.u. ', fontsize=12)\n",
    "    plt.ylabel('Abundance / a.u. ', fontsize=12)\n",
    "    plt.title(f\"FEL pulse intensity histogram (run number {file_list[run_number]})\", fontsize = 16)\n",
    "    \n",
    "    directory=os.chdir(r\"/home/merrickj/Documents/indene_BID_filter_check_plots\")\n",
    "    #directory=os.chdir(r\"/home/merrickj/Documents/fluorene_BID_filter_check_plots\")\n",
    "    #directory=os.chdir(r\"/home/merrickj/Documents/CPP_BID_filter_check_plots\")\n",
    "    \n",
    "    mu_FEL = round(np.mean(energies), 2) # rounds to 2 d.p. for ease of comparison between runs\n",
    "    print(f\"Mean calculated for run number {file_list[run_number]}: {mu_FEL}\")\n",
    "    std_FEL = round(np.std(energies), 2) # rounds to 2 d.p. for ease of comparison between runs\n",
    "    print(f\"Standard deviation calculated for run number {file_list[run_number]}: {std_FEL}\")\n",
    "    \n",
    "    textstr = '\\n'.join((\n",
    "    r'$\\mu=%.2f$' % (mu_FEL, ),\n",
    "    r'$\\sigma=%.2f$' % (std_FEL, )))\n",
    "    \n",
    "    props = dict(boxstyle='round', facecolor='white', alpha=0.5)\n",
    "    ax.text(0.05, 0.95, textstr, transform=ax.transAxes, fontsize=14,\n",
    "    verticalalignment='top', bbox=props)\n",
    "    \n",
    "    answer = input(\"Do you want to save the FEL histogram as a .png file (y/n)?\")\n",
    "    if answer in ['y', 'Y', 'yes', 'Yes', 'YES']:\n",
    "    \n",
    "        plt.savefig(f\"FEL_histogram_{file_list[run_number]}.png\", bbox_inches=\"tight\")\n",
    "\n",
    "    FEL_lower = mu_FEL - (2*std_FEL) # mu - 2*sigma\n",
    "    FEL_higher = mu_FEL + (2*std_FEL) # mu + 2*sigma\n",
    "    \n",
    "    mu_list.append(mu_FEL)\n",
    "    std_list.append(std_FEL)\n",
    "    FEL_lower_list.append(FEL_lower)\n",
    "    FEL_higher_list.append(FEL_higher)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Filtering BID-filtered data by FEL pulse intensity (filtering rows with FEL pulse intensities ~ 1 sigma away from mean\n",
    "#    FEL pulse intensity, found roughly in the centre of the histogram above). (JHM)\n",
    "\n",
    "FEL_BID_filtered_df_list = []\n",
    "\n",
    "for run_number, BID_filtered_df in enumerate(BID_filtered_df_list): # just looping over every BID-filtered dataframe in list\n",
    "    \n",
    "    FEL_lower = FEL_lower_list[run_number]\n",
    "    FEL_higher = FEL_higher_list[run_number]\n",
    "    \n",
    "    FEL_BID_filtered_df = BID_filtered_df[(BID_filtered_df['Energy'] >= FEL_lower) & (BID_filtered_df['Energy'] <= FEL_higher)]\n",
    "    FEL_BID_filtered_df_list.append(FEL_BID_filtered_df)\n",
    "    \n",
    "    print(FEL_BID_filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6a. Plot time-of-flight spectra for each run on same plot\n",
    "#    Adapted from: \"on the fly ion images + delay + rdf NOT CENTROIDED v6 EMW C4H4Se.ipynb\"\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "plt.xlabel('Time-of-flight / a.u.', fontsize=14)\n",
    "plt.tick_params(axis='x', labelsize=12)\n",
    "plt.ylabel('Intensity / a.u.', fontsize=14)\n",
    "plt.tick_params(axis='y', labelsize=12)\n",
    "ax.set_xlim(2050,2500) # alter as necessary for molecule of interest\n",
    "ax.grid(which='major')\n",
    "ax.grid(which='minor')\n",
    "ax.minorticks_on()\n",
    "tof_appended = []\n",
    "\n",
    "#for df,file in zip(FEL_BID_filtered_df_list,file_list):\n",
    "for df,file in zip(centroided_df_list,file_list):\n",
    "    plt.title('Run-separated ToF spectrum')\n",
    "    df = df[(df['ToF']>2000) & (df['ToF']<2500)]\n",
    "    tof = df.groupby(['ToF']).size().reset_index(name='intensity')\n",
    "    tof_times_list = tof['ToF'].to_list()\n",
    "    #print(tof)\n",
    "    tof_appended.append(tof)\n",
    "    plt.plot(tof.ToF,tof.intensity,label=str(file))\n",
    "    ax.legend(loc='upper right', fontsize=18)\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "#fig.savefig(f\"indene_run_separated_tof_spectrum.png\", bbox_inches=\"tight\")\n",
    "#fig.savefig(f\"fluorene_run_separated_tof_spectrum.png\", bbox_inches=\"tight\")\n",
    "#fig.savefig(f\"CPP_run_separated_tof_spectrum.png\", bbox_inches=\"tight\")\n",
    "fig.savefig(f\"fluorene_run_separated_tof_spectrum.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6b. Calibration of TOF spectrum to convert from TOF-domain to m/z domain (user input for predicted m/z values and corresponding\n",
    "#     TOF values from previous TOF spectrum assignment) via linear-regression. Add extra column to df for m/z values using linear\n",
    "#     regression parameters obtained, and plot m/z-domain spectrum.\n",
    "#     Adapted from: \"on the fly ion images + delay + rdf NOT CENTROIDED v6 EMW C4H4Se.ipynb\"\n",
    "\n",
    "# For FLU - the uncommented calibration points work well so do not change!\n",
    "# ToF_list = [(2275,2285),(2380,2400),(2423,2426),(2217,2223),(2248,2252),(2300,2310),(2458,2459)] # known TOF windows for ions seen in TOF spectrum above - more windows = better calib.!\n",
    "# ion_list=['C4', 'C9', 'C11','C2','C3','C5','$C_{13}H_{10}^{+}$']\n",
    "# mz_arr=np.array([51,116,140,27,39,64,166]) # approximate m/z values we would expect for above ions\n",
    "# ToF_list = [(2085,2087),(2117,2219),(2190,2192),(2192,2194),(2195,2197),(2219,2221),(2249,2251),(2279,2281),(2289,2291),(2304,2306),(2317,2319),(2324,2326),(2339,2341),(2347,2349),(2366,2368),(2391,2393),(2422,2424),(2456.5,2457.5),(2458,2458.5),(2458,2460)]\n",
    "# ion_list_total = ['$H^{+}$','$He^{+}$','$O^{+}$','$OH^{+}$','$H_{2}O^{+}$','C2','C3','C4', '$C_{13}H_{9}^{3+}$','C5','$C_{11}H_{7}^{2+}$','C6','$C_{13}H_{x}^{2+}$', 'C8', 'C9','C10', 'C11','$C_{13}H_{7}^{+}$','$C_{13}H_{9}^{+}$','$C_{13}H_{10}^{+}$']\n",
    "# mz_arr = np.array([1,4,16,17,18,27,39,51,55,64,70,76,82.5,100,116,128,140,163,165,166])\n",
    "\n",
    "# for fluorene, 2018 data\n",
    "# ToF_list = [(2085,2087),(2458,2460)]\n",
    "# ion_list = ['$H^{+}$','$C_{13}H_{10}^{+}$']\n",
    "# mz_arr = np.array([1,166])\n",
    "\n",
    "# for triphenylene, 2021 data \n",
    "#ToF_list = [(1009,1011),(1312,1314)]\n",
    "#ion_list = ['$H^{+}$','$C_{18}H_{12}^{+}$']\n",
    "#mz_arr = np.array([1,228])\n",
    "\n",
    "# for fluorene, 2023 data\n",
    "# ToF_list = [(1613, 1616),(1617, 1621),(1631, 1634),(1643, 1646),(1650, 1652), (1657, 1662),(1662,1671),(1670, 1673), (1679,1683),(1688,1695),(1699,1705), (1708,1714), (1716,1723), (1725,1735),(1734,1741),(1743,1750), (1749,1755),(1756,1765),(1770,1776),(1783,1793), (1794,1803), (1810,1816),(1831,1841)]\n",
    "# ion_list = ['N(++)','O(++)','C2(++)','O(+)','water(+)','carbon_dioxide(++)','C2(+)','dinitrogen(+)','dioxygen(+)','C3(+)','carbon_dioxide(+)','C4(+)','PAH(+++)','C5(+)','C11(++)','C6(+)','PAH(++)','C7(+)','C8(+)','C9(+)','C10(+)','C11(+)','PAH-H(+)']\n",
    "# mz_arr = np.array([7,8,12,16,18,22,26,28,32,38,44,50,55.5,63,70,75,83,88,100,116,127,141,165])\n",
    "\n",
    "# for indene, 2023 data \n",
    "#ToF_list = [(1789,1791),(1760,1763),(1743,1746),(1728,1730),(1721,1723),(1711,1713),(1700,1702),(1691,1693)]\n",
    "#ion_list = ['indene(+)','C7(+)','C6(+)','C5(+)','indene(2+)','C4(+)','C7(2+)','C3(+)']\n",
    "#mz_arr = np.array([116.2,87,75,62,58.1,50,43.5,38])\n",
    "\n",
    "# for fluorene, 2023 data\n",
    "# ToF_list = [(1831,1840),(1820,1830),(1810,1818),(1798,1802),(1780,1792),(1770,1778),(1755,1765),(1750,1752),(1742,1749),(1735,1740),(1725,1733),(1720,1722),(1707,1715),(1699,1704),(1685,1698),(1662,1672),(1630,1633)]\n",
    "# ion_list = ['FLU(+)','C12(+)','C11(+)','C10(+)','C9(+)','C8(+)','C7(+)','FLU(++)','C6(+)','C11(++)','C5(+)','FLU(+++)/C9(++)','C4(+)','C3(+)','C7(++)/FLU(++++)','C2(+)','C1(+)']\n",
    "# mz_arr = np.array([166,150,137,125,113,100,87,83,75,68,62,55,50,38,42,26,13])\n",
    "\n",
    "# for CPP, 2023 data\n",
    "ToF_list = [(1631,1636),(1665,1671),(1686,1694),(1701,1707),(1710,1715),(1718,1722),(1725,1733),(1736,1740),(1742,1749),(1752,1754),(1757,1765),(1766,1770),(1772,1778),(1780,1791),(1795,1805),(1806,1815),(1820,1828),(1830,1838),(1842,1850),(1851,1860),(1864,1869)]\n",
    "ion_list = ['C1','C2','C3','CPP(4+)','C4','C9(2+)','C5','C11(2+)','C6','C13(2+)','C7','CPP(2+)','C8','C9','C10','C11','C12','C13','C14','CPP(+)','[CPP-dinitrogen](+)']\n",
    "mz_arr = np.array([12,26,38,47.56,50,56.5,62,68,74,81.5,87,95.12,98,113,125,136,151,163,176,190.24,204])\n",
    "\n",
    "print(\"m/z array size: \" + str(mz_arr.size))\n",
    "print(\"ToF array size: \" + str(len(ToF_list)))\n",
    "print(\"ion array size: \" + str(len(ion_list)))\n",
    "\n",
    "# Linear regression\n",
    "t_list=[]\n",
    "for (ti,tf) in ToF_list:\n",
    "    t_list.append((ti+tf)/2)\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(10,4))\n",
    "sqmz_arr = np.sqrt(mz_arr)\n",
    "plt.scatter(t_list, sqmz_arr, marker='x', color='red', s=150)\n",
    "ax.set_xlim(min(t_list)-5,max(t_list)+5)\n",
    "ax.set_ylim(min(sqmz_arr)-1, max(sqmz_arr)+1)\n",
    "fit = np.polyfit(t_list,  sqmz_arr, deg=1)\n",
    "fit2 = np.polyfit(sqmz_arr, t_list, deg=1)\n",
    "print('ToF fitted params:')\n",
    "print(fit)\n",
    "print(fit2)\n",
    "plt.plot(fit[0]*np.arange(15000)+fit[1],color='blue',linewidth=2)\n",
    "ax.set_xlim(min(t_list)-100,max(t_list)+100)\n",
    "ax.set_xlabel('ToF / a.u.', fontsize=14)\n",
    "ax.set_ylabel('${\\sqrt{m/z}}$', fontsize=14)\n",
    "plt.tick_params(axis='x', labelsize=12)\n",
    "plt.tick_params(axis='y', labelsize=12)\n",
    "\n",
    "#plt.title('Indene - time-of-flight mass calibration', fontsize=16)\n",
    "#plt.title('Fluorene - time-of-flight mass calibration', fontsize=16)\n",
    "plt.title('CPP - time-of-flight mass calibration', fontsize=16)\n",
    "\n",
    "#fig.savefig(f\"indene_mass_calibration.png\", bbox_inches=\"tight\")\n",
    "#fig.savefig(f\"fluorene_mass_calibration.png\", bbox_inches=\"tight\")\n",
    "fig.savefig(f\"CPP_mass_calibration.png\", bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f\"H+ calibrated m/z: {(fit[0]*1580 + fit[1])**2}\")\n",
    "print(f\"He+ calibrated m/z: {(fit[0]*1602 + fit[1])**2}\")\n",
    "print(f\"{(fit[0]*1856 + fit[1])**2}\")\n",
    "\n",
    "for df,file in zip(FEL_BID_filtered_df_list,file_list):\n",
    "    \n",
    "    df['m_z'] = (fit[0]*df['ToF'] + fit[1])**2 # appending m/z column to each df\n",
    "    df['m_z'] = round(2*df['m_z'])/2 # rounding m/z values to nearest 0.5\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6c. Plot time-of-flight spectra for each run on same plot, this time in m/z domain. This plot can then be used to identify\n",
    "#    more fragments of interest (to then cross-reference their ToF values in initial ToF spectrum). (JHM)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "plt.xlabel('m/z', fontsize=14)\n",
    "plt.tick_params(axis='x', labelsize=12)\n",
    "plt.ylabel('Intensity / a.u.', fontsize=14)\n",
    "plt.tick_params(axis='y', labelsize=12)\n",
    "ax.set_xlim(0,210) # alter as necessary for molecule of interest\n",
    "ax.grid(which='major')\n",
    "ax.grid(which='minor')\n",
    "ax.minorticks_on()\n",
    "tof_appended = []\n",
    "\n",
    "for df,file in zip(FEL_BID_filtered_df_list,file_list):\n",
    "    plt.title('Run-separated ToF spectrum (mass-calibrated)')\n",
    "    df = df[(df['m_z']>0) & (df['m_z']<210)]\n",
    "    tof = df.groupby(['m_z']).size().reset_index(name='intensity')\n",
    "    plt.plot(tof.m_z,tof.intensity,label=str(file))\n",
    "    ax.legend(loc='upper right', fontsize=18)\n",
    "    tof_times_list = tof['m_z'].to_list()\n",
    "    tof_appended.append(tof)\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "#fig.savefig(f\"indene_run_separated_tof_spectrum_m_z.png\", bbox_inches=\"tight\")\n",
    "#fig.savefig(f\"fluorene_run_separated_tof_spectrum_m_z.png\", bbox_inches=\"tight\")\n",
    "fig.savefig(f\"CPP_run_separated_tof_spectrum_m_z.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 7. Normalising delay bins by number of shots in each bin. For each delay, we want to find how many unique tIds there are, and\n",
    "#     normalise by that amount. This produces fully corrected ion-yield plots - no more processing needs to be done. (JHM)\n",
    "\n",
    "# indene, 2023 data\n",
    "#ToF_list = [(1632,1633),(1665,1675),(1692,1694),(1700,1702),(1710,1712),(1720,1722),(1728,1730),(1743,1746),(1760,1762),(1789,1791)]\n",
    "#ion_list = ['C1','C2','C3','C7(2+)','C4','IND(2+)','C5','C6','C7','IND(+)']\n",
    "\n",
    "# fluorene, 2023 data\n",
    "# ToF_list = [(1831,1840),(1820,1830),(1810,1818),(1798,1802),(1780,1792),(1770,1778),(1755,1765),(1750,1752),(1742,1749),(1735,1740),(1725,1733),(1720,1722),(1707,1715),(1699,1704),(1685,1698),(1662,1672),(1630,1633)]\n",
    "# ion_list = ['FLU(+)','C12(+)','C11(+)','C10(+)','C9(+)','C8(+)','C7(+)','FLU(++)','C6(+)','C11(++)','C5(+)','FLU(+++)/C9(++)','C4(+)','C3(+)','C7(++)/FLU(++++)','C2(+)','C1(+)']\n",
    "\n",
    "# CPP, 2023 data\n",
    "ToF_list = [(1631,1636),(1665,1671),(1686,1694),(1701,1707),(1710,1715),(1718,1722),(1725,1733),(1736,1740),(1742,1749),(1752,1754),(1757,1765),(1766,1770),(1772,1778),(1780,1791),(1795,1805),(1806,1815),(1820,1828),(1830,1838),(1842,1850),(1851,1860),(1864,1869)]\n",
    "ion_list = ['C1','C2','C3','CPP(4+)','C4','C9(2+)','C5','C11(2+)','C6','C13(2+)','C7','CPP(2+)','C8','C9','C10','C11','C12','C13','C14','CPP(+)','[CPP-dinitrogen](+)']\n",
    "\n",
    "def TOF_filter(df, ti, tf): # function from \"centroid files with delay.ipynb\"\n",
    "    df_filt = df[(df['ToF'] >= ti) & (df['ToF'] <= tf)]\n",
    "    return(df_filt)\n",
    "\n",
    "for run_number, FEL_BID_filtered_df in enumerate(FEL_BID_filtered_df_list): # loop over run numbers\n",
    "    \n",
    "    round_delay_array = np.unique(FEL_BID_filtered_df['Delay_round']).tolist() # unique delay values in run number data\n",
    "    no_shots_per_round_delay = []\n",
    "\n",
    "    for delay in round_delay_array: # loop over each delay value\n",
    "        FEL_BID_filtered_df_delay = FEL_BID_filtered_df[(FEL_BID_filtered_df['Delay_round'] == delay)]\n",
    "        number_of_shots = len(np.unique(FEL_BID_filtered_df_delay['BID'])) # number of shots per delay value\n",
    "        no_shots_per_round_delay.append(number_of_shots)\n",
    "\n",
    "    # print(round_delay_array)\n",
    "    # print(no_shots_per_round_delay)\n",
    "    # print(len(round_delay_array))\n",
    "    # print(len(no_shots_per_round_delay))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (10,8))\n",
    "    ax.bar(round_delay_array,no_shots_per_round_delay, width = 0.09, align = 'center') # for ALL ions\n",
    "    ax.set_xlabel('Delay / ps')\n",
    "    \n",
    "    #ax.set_title(f\"Delay v.s. number of shots (run-concatenated) - indene\", fontsize = 16)\n",
    "    ax.set_title(f\"Delay v.s. number of shots (run-concatenated) - fluorene\", fontsize = 16)\n",
    "    \n",
    "    ax.set_ylabel('Number of shots')\n",
    "    ax.grid(which='major')\n",
    "    ax.grid(which='minor')\n",
    "    ax.minorticks_on()\n",
    "    #fig.savefig(f\"indene_delay_intensity_bargraph\",bbox_inches=\"tight\")\n",
    "\n",
    "    df_delay_vs_no_shots = pd.DataFrame()\n",
    "    df_delay_vs_no_shots['Delay_round'] = round_delay_array\n",
    "    df_delay_vs_no_shots['No_of_shots'] = no_shots_per_round_delay\n",
    "    # print(df_delay_vs_no_shots)\n",
    "\n",
    "    #directory=os.chdir(r\"/home/merrickj/Documents/indene_ion_yields\")\n",
    "    #directory=os.chdir(r\"/home/merrickj/Documents/fluorene_ion_yields\")\n",
    "    directory=os.chdir(r\"/home/merrickj/Documents/CPP_ion_yields\")\n",
    "    \n",
    "    for i, (ti, tf) in enumerate(ToF_list): # plotting ion yields for separate run numbers\n",
    "        ion = ion_list[i]\n",
    "        FEL_BID_filtered_df_filt = TOF_filter(FEL_BID_filtered_df, ti, tf) # for dual-filtered data; filter by ToF\n",
    "        ion_yield = FEL_BID_filtered_df_filt.groupby(['Delay_round']).size().reset_index(name='ion_yield')\n",
    "        ion_yield = ion_yield.merge(df_delay_vs_no_shots,on = 'Delay_round')\n",
    "        ion_yield['delay_normalised_yield'] = ion_yield['ion_yield']/ion_yield['No_of_shots']\n",
    "    #     print(ion_yield)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize = (10,8))\n",
    "        ax.scatter(ion_yield.Delay_round, ion_yield.delay_normalised_yield)\n",
    "\n",
    "        ax.set_xlabel('Delay / ps')\n",
    "        ax.set_title(f\"Ion-yield for {ion} (file: {file_list[run_number]})\", fontsize=16)\n",
    "        ax.set_ylabel('Ion-yield / a.u.')\n",
    "        \n",
    "        #fig.savefig(f\"ion_yield_{i}_run_{file_list[run_number]}\",bbox_inches=\"tight\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Saving filtered and processed data as .npy arrays, and concatenating relevant run numbers to make a larger .npy file. (JHM)\n",
    "\n",
    "#directory=os.chdir(r\"/home/merrickj/Documents/indene_filtered_data_for_covariance\")\n",
    "#directory=os.chdir(r\"/home/merrickj/Documents/fluorene_filtered_data_for_covariance\")\n",
    "#directory=os.chdir(r\"/home/merrickj/Documents/CPP_filtered_data_for_covariance\")\n",
    "\n",
    "directory=os.chdir(r\"/home/merrickj/Documents/fluorene_2018_all\")\n",
    "\n",
    "#for run_number, FEL_BID_filtered_df in enumerate(FEL_BID_filtered_df_list):\n",
    "for run_number, FEL_BID_filtered_df in enumerate(centroided_df_list):\n",
    "    print(FEL_BID_filtered_df)\n",
    "    array = FEL_BID_filtered_df.to_numpy()\n",
    "    np.save(f\"{file_list[run_number]}.npy\",array)\n",
    "    print(f\"Saved run number {file_list[run_number]} to numpy array\")\n",
    "    \n",
    "concatenate_answer_centroided = input(\"Do you wish to concatenate all files to make one large .npy file (y/n)?\")\n",
    "\n",
    "if concatenate_answer_centroided in ['y', 'Y', 'yes', 'Yes', 'YES']:\n",
    "    \n",
    "    #full_data_centroided = pd.concat(FEL_BID_filtered_df_list, axis=0) # makes one large dataframe\n",
    "    full_data_centroided = pd.concat(centroided_df_list, axis=0) # makes one large dataframe\n",
    "    print(full_data_centroided)\n",
    "    \n",
    "    full_data_centroided_array = full_data_centroided.to_numpy()\n",
    "    \n",
    "    np.save(f\"fluorene_full_data_centroided_uncorrected.npy\",full_data_centroided_array)\n",
    "    #np.save(f\"fluorene_full_data_centroided_corrected.npy\",full_data_centroided_array)\n",
    "    #np.save(f\"CPP_full_data_centroided_corrected.npy\",full_data_centroided_array)\n",
    "    \n",
    "    print(f\"Saved numpy array of concatenated data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 9. From the concatenated data file, print run-concatenated ion-yield v.s. delay plots (JHM)\n",
    "\n",
    "round_delay_array = np.unique(full_data_centroided['Delay_round']).tolist() # unique delay values in run number data\n",
    "print(f\"Total numbebr of unique BIDs (total number of shots) in concatenated dataframe: {len(np.unique(full_data_centroided['BID']))}\")\n",
    "no_shots_per_round_delay = []\n",
    "\n",
    "for delay in round_delay_array: # loop over each delay value\n",
    "    FEL_BID_filtered_df_delay = full_data_centroided[(full_data_centroided['Delay_round'] == delay)]\n",
    "    number_of_shots = len(np.unique(FEL_BID_filtered_df_delay['BID'])) # number of shots per delay value\n",
    "    print(f\"Number of shots for delay {delay}: {number_of_shots}\")\n",
    "    no_shots_per_round_delay.append(number_of_shots)\n",
    "\n",
    "# print(round_delay_array)\n",
    "# print(no_shots_per_round_delay)\n",
    "# print(len(round_delay_array))\n",
    "# print(len(no_shots_per_round_delay))\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,8))\n",
    "ax.bar(round_delay_array,no_shots_per_round_delay, width = 0.04, align = 'center') # for ALL ions\n",
    "ax.set_xlabel('Delay / ps')\n",
    "\n",
    "#ax.set_title(f\"Delay v.s. number of shots (run-concatenated) - indene\", fontsize = 16)\n",
    "#ax.set_title(f\"Delay v.s. number of shots (run-concatenated) - fluorene\", fontsize = 16)\n",
    "ax.set_title(f\"Delay v.s. number of shots (run-concatenated) - CPP\", fontsize = 16)\n",
    "\n",
    "ax.set_ylabel('Number of shots')\n",
    "ax.grid(which='major')\n",
    "ax.grid(which='minor')\n",
    "ax.minorticks_on()\n",
    "\n",
    "#fig.savefig(f\"indene_delay_intensity_bargraph.png\",bbox_inches=\"tight\")\n",
    "#fig.savefig(f\"fluorene_delay_intensity_bargraph.png\",bbox_inches=\"tight\")\n",
    "fig.savefig(f\"CPP_delay_intensity_bargraph.png\",bbox_inches=\"tight\")\n",
    "\n",
    "df_delay_vs_no_shots = pd.DataFrame()\n",
    "df_delay_vs_no_shots['Delay_round'] = round_delay_array\n",
    "df_delay_vs_no_shots['No_of_shots'] = no_shots_per_round_delay\n",
    "# print(df_delay_vs_no_shots)\n",
    "\n",
    "#directory=os.chdir(r\"/home/merrickj/Documents/indene_ion_yields\")\n",
    "#directory=os.chdir(r\"/home/merrickj/Documents/fluorene_ion_yields\")\n",
    "directory=os.chdir(r\"/home/merrickj/Documents/CPP_ion_yields\")\n",
    "\n",
    "for i, (ti, tf) in enumerate(ToF_list): # plotting ion yields for separate run numbers\n",
    "    ion = ion_list[i]\n",
    "    FEL_BID_filtered_df_filt = TOF_filter(full_data_centroided, ti, tf) # for dual-filtered data; filter by ToF\n",
    "    ion_yield = FEL_BID_filtered_df_filt.groupby(['Delay_round']).size().reset_index(name='ion_yield')\n",
    "    ion_yield = ion_yield.merge(df_delay_vs_no_shots,on = 'Delay_round')\n",
    "    ion_yield['delay_normalised_yield'] = ion_yield['ion_yield']/ion_yield['No_of_shots']\n",
    "    \n",
    "    delay_round_to_plot = ion_yield['Delay_round'].to_list()\n",
    "    delay_normalised_yield_to_plot = ion_yield['delay_normalised_yield'].to_list()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (10,8))\n",
    "    ax.scatter(delay_round_to_plot[:-2], delay_normalised_yield_to_plot[:-2])\n",
    "\n",
    "    ax.set_xlabel('Delay / ps')\n",
    "    \n",
    "    #ax.set_title(f\"Ion-yield v.s. pump-probe delay for {ion} (run-concatenated) - indene\", fontsize=16)\n",
    "    #ax.set_title(f\"Ion-yield v.s. pump-probe delay for {ion} (run-concatenated) - fluorene\", fontsize=16)\n",
    "    ax.set_title(f\"Ion-yield v.s. pump-probe delay for {ion} (run-concatenated) - fluorene\", fontsize=16)\n",
    "    \n",
    "    ax.set_ylabel('Ion-yield / a.u.')\n",
    "    #ax.set_xlim(92.7,94.0)\n",
    "\n",
    "    fig.savefig(f\"ion_yield_{i}_runconcatenated_total\",bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10a. (Optional) for saving concatenated uncentroided data (JHM)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "def read_bin_torder(filename):\n",
    "    \n",
    "    directory=os.chdir(r\"/asap3/flash/gpfs/bl1/2023/data/11013421/raw/PImMS/\")\n",
    "    file = open(str(filename)+'.bin', 'rb')\n",
    "    xyt_data = []\n",
    "\n",
    "    delays = 1000*((np.loadtxt(str(filename)+'-settings.txt', usecols=[3]))) # read in settings file and chooses delay value\n",
    "    delays = delays.astype(int)\n",
    "    BID = np.around(np.loadtxt(filename+'-settings.txt', usecols=[0]),3) # reads in BID values from settings file\n",
    "    BID = BID.astype(int)\n",
    "    \n",
    "    lasershot=0\n",
    "    \n",
    "    for block,d,b in zip(iter(lambda: file, ''),delays,BID):\n",
    "\n",
    "        try:\n",
    "            m, n = np.fromfile(file, dtype='<i', count=2)\n",
    "            frame = np.reshape(np.fromfile(file, dtype='<u2', count=m*n), (m, n))\n",
    "            lasershot += 1\n",
    "            if len(frame)>0:\n",
    "\n",
    "                ls_col = np.zeros((len(frame),1), dtype='int16')\n",
    "                ls_col = ls_col + lasershot\n",
    "                frame = np.append(frame,ls_col,1) # appends counter-generated tag IDs (starting from 0) to array\n",
    "\n",
    "                col_zeros = np.zeros((len(frame),1), dtype='int16')\n",
    "                col_tId = col_zeros + b\n",
    "                frame = np.append(frame,col_tId,axis=1) # appends settings file BIDs to array\n",
    "\n",
    "                col_zeros = np.zeros((len(frame),1), dtype='int16')\n",
    "                col_delays = col_zeros + d\n",
    "                frame = np.append(frame,col_delays,axis=1) # appends delay values to array\n",
    "                frame = frame[frame[:,2].argsort()] # orders by time-of-flight\n",
    "                xyt_data.append(frame)\n",
    "        except ValueError:\n",
    "            break\n",
    "    file.close()\n",
    "    return np.vstack(xyt_data)\n",
    "\n",
    "#file_list=['222','223','224','226','227'] # run numbers for indene 2023\n",
    "#file_list = ['147','148','150','151'] # run numbers for fluorene 2023\n",
    "file_list = ['129','130'] # run numbers for CPP 2023\n",
    "\n",
    "centroided_df_list = []\n",
    "\n",
    "for f in file_list:\n",
    "    counter=1\n",
    "    print('opening file '+ str(f))\n",
    "    start_time = time.time()\n",
    "    xyt=read_bin_torder(f)\n",
    "    xyt_df=pd.DataFrame(xyt, columns=['x','y','ToF','counter_tagID','BID','delay'])\n",
    "    print(xyt_df)\n",
    "    centroided_df_list.append(xyt_df)\n",
    "    print(\"Opening took %s seconds\" % round((time.time()-start_time),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Then run cells 2, 4 and 5 to get BID- and FEL-filtered data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10b. (Optional) for saving concatenated uncentroided data (after BID- and FEL-filtering) (JHM)\n",
    "\n",
    "#directory=os.chdir(r\"/home/merrickj/Documents/indene_filtered_data_for_covariance\")\n",
    "#directory=os.chdir(r\"/home/merrickj/Documents/fluorene_filtered_data_for_covariance\")\n",
    "directory=os.chdir(r\"/home/merrickj/Documents/CPP_filtered_data_for_covariance\")\n",
    "\n",
    "full_data = pd.concat(FEL_BID_filtered_df_list, axis=0) # makes one large dataframe\n",
    "print(full_data)\n",
    "\n",
    "answer2 = input(\"Do you want to save just one frame's worth of data (y/n)?\")\n",
    "\n",
    "if answer2 in ['y', 'Y', 'yes', 'Yes', 'YES']: # for just for one BID/tId frame saving\n",
    "    \n",
    "    first_tId = full_data['BID'].iloc[0]\n",
    "    df_test = full_data[(full_data['BID'] == first_tId)]\n",
    "    print(df_test)\n",
    "\n",
    "    full_data_array = df_test.to_numpy()\n",
    "    \n",
    "    #np.save(f\"indene_full_data_uncentroided_corrected_justoneBID.npy\",full_data_array)\n",
    "    #np.save(f\"fluorene_full_data_uncentroided_corrected_justoneBID.npy\",full_data_array)\n",
    "    np.save(f\"CPP_full_data_uncentroided_corrected_justoneBID.npy\",full_data_array)\n",
    "    \n",
    "    print(f\"Saved numpy array of concatenated data.\")\n",
    "    \n",
    "elif answer2 in ['n', 'N', 'no', 'No', 'NO']:\n",
    "    \n",
    "    full_data_array = full_data.to_numpy()\n",
    "    \n",
    "    #np.save(f\"indene_full_data_uncentroided_corrected.npy\",full_data_array)\n",
    "    #np.save(f\"fluorene_full_data_uncentroided_corrected.npy\",full_data_array)\n",
    "    np.save(f\"CPP_full_data_uncentroided_corrected.npy\",full_data_array)\n",
    "    \n",
    "    print(f\"Saved numpy array of concatenated data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

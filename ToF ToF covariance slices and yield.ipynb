{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Script adapted from \"ToF ToF covariance slices and yield.ipynb\" (by Tiffany Walmsley, Burt Group) ###\n",
    "\n",
    "# 1. Imports and functions\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.signal import savgol_filter\n",
    "from numba import njit\n",
    "import h5py\n",
    "\n",
    "u = 1.66e-27\n",
    "e = 1.6e-19\n",
    "\n",
    "def create_vel_image(df, nbins, bin_size, Ti = 0, Tf = 0):\n",
    "    \n",
    "    if (Ti & Tf):\n",
    "        df = df[(df['ToF'] >= Ti) & (df['ToF'] <= Tf)]\n",
    "    xedges = np.arange(-nbins/2, nbins/2)*bin_size\n",
    "    yedges = np.arange(-nbins/2, nbins/2)*bin_size\n",
    "    H, xedges, yedges = np.histogram2d(df['vx'], df['vy'], bins = (xedges, yedges))\n",
    "    \n",
    "    return(H, xedges, yedges)\n",
    "\n",
    "def create_pos_image(df, nbins, bin_size, Ti = 0, Tf = 0):\n",
    "    \n",
    "    if (Ti & Tf):\n",
    "        df = df[(df['ToF'] >= Ti) & (df['ToF'] <= Tf)]\n",
    "    xedges = np.arange(-nbins/2, nbins/2 + 1)*bin_size\n",
    "    yedges = np.arange(-nbins/2, nbins/2 + 1)*bin_size\n",
    "    H, xedges, yedges = np.histogram2d(df['x'], df['y'], bins = (xedges, yedges))\n",
    "    \n",
    "    return(H, xedges, yedges)\n",
    "    \n",
    "def create_ToF(df, n_bins, min_t = 0, max_t = 0):\n",
    "    \n",
    "    if (max_t):\n",
    "        intensity, bin_edges = np.histogram(df.ToF, n_bins, range = (min_t, max_t))\n",
    "    else:\n",
    "        intensity, bin_edges = np.histogram(df.ToF, n_bins)\n",
    "    mid_values = (bin_edges[:-1] + (bin_edges[1] - bin_edges[0])/2)\n",
    "    \n",
    "    return(mid_values, intensity)\n",
    "\n",
    "def create_p_dist(p, n_bins, min_p = 0, max_p = 0):\n",
    "    \n",
    "    if (max_p):\n",
    "        intensity,bin_edges = np.histogram(p, n_bins, range = (min_p, max_p))\n",
    "    else:\n",
    "        intensity,bin_edges = np.histogram(p, n_bins)\n",
    "    mid_values = (bin_edges[:-1] + (bin_edges[1] - bin_edges[0])/2)\n",
    "    \n",
    "    return(mid_values, intensity)\n",
    "\n",
    "def beautify(ax, param_dict):\n",
    "    \n",
    "    ax.tick_params(labelsize = param_dict['tick_label_size'],\n",
    "                   length = param_dict['tick_length'],\n",
    "                   width = param_dict['tick_width'])\n",
    "    \n",
    "    ax.xaxis.get_label().set_fontsize(param_dict['axis_label_size'])\n",
    "    ax.yaxis.get_label().set_fontsize(param_dict['axis_label_size'])\n",
    "    \n",
    "    for axis in ['top', 'bottom', 'left', 'right']:\n",
    "        ax.spines[axis].set_linewidth(param_dict['spine_width'])\n",
    "\n",
    "# param_dict = {'spine_width':1,\n",
    "#               'line_width':2,\n",
    "#               'tick_length':3,\n",
    "#               'tick_width':1,\n",
    "#               'tick_label_size':12,\n",
    "#               'axis_label_size':12}\n",
    "\n",
    "# plt.rcParams[\"font.family\"] = \"serif\"\n",
    "# plt.rcParams['mathtext.fontset'] = 'stix'\n",
    "\n",
    "@njit\n",
    "def reindex_shots(shot_list):\n",
    "    \n",
    "    for i, shot in enumerate(shot_list):\n",
    "        if shot == shot_list[i+1]: continue\n",
    "        if shot == shot_list[i+1]-1: continue \n",
    "        if shot != shot_list[i+1]-1:\n",
    "            shot_list[i+1:] -= (shot_list[i+1] - shot)\n",
    "            \n",
    "    return(shot_list)\n",
    "\n",
    "\n",
    "def p_calibration(m_list, q_list, ToF_list, ToF_range_list):\n",
    "    \n",
    "    SI_to_au = 1.992e-24\n",
    "    ion_df_list = []\n",
    "\n",
    "    for ToF, m, q, (Ti,Tf) in zip(ToF_list, m_list, q_list, ToF_range_list):\n",
    "\n",
    "        m *= u\n",
    "\n",
    "        # Collect data\n",
    "        ion_df = (event_df[(event_df['ToF'] >= Ti) & (event_df['ToF'] <= Tf)]).copy()\n",
    "        ion_df['ToF_SI_cal'] = (ion_df['ToF'] - ion_T0)*1e-9\n",
    "\n",
    "        ion_df['px_SI'] = ion_df['x']*0.826*m/ion_df['ToF_SI_cal']\n",
    "        ion_df['py_SI'] = ion_df['y']*0.826*m/ion_df['ToF_SI_cal']\n",
    "        ion_df['pz_SI'] = -1.9e-15*2*q*((ion_df['ToF'] - ToF)*1e-9)\n",
    "        ion_df['pmag_SI'] = np.sqrt(ion_df['pz_SI']**2 + ion_df['py_SI']**2 + ion_df['px_SI']**2)\n",
    "\n",
    "        for column_pair in [('px_AU', 'px_SI'), ('py_AU', 'py_SI'), ('pz_AU', 'pz_SI'), ('pmag_AU', 'pmag_SI')]:\n",
    "            ion_df[column_pair[0]] = ion_df[column_pair[1]]/SI_to_au\n",
    "\n",
    "        ion_df['pr_AU'] = np.sqrt(ion_df['px_AU']**2 + ion_df['py_AU']**2)\n",
    "\n",
    "        ion_df_list.append(ion_df)\n",
    "\n",
    "    return(ion_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Loading in data \n",
    "\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_rows', 4096) # Controls number of lines displayed (PImMS maximum = 4096 timebins)\n",
    "\n",
    "#directory=os.chdir(r\"/home/merrickj/Documents/indene_filtered_data_for_covariance\")\n",
    "directory=os.chdir(r\"/home/merrickj/Documents/fluorene_filtered_data_for_covariance\")\n",
    "#directory=os.chdir(r\"/home/merrickj/Documents/CPP_filtered_data_for_covariance\")\n",
    "\n",
    "#file_list = ['038','039','040','041','042','043','044'] # run number; adapt to supply an array of run numbers whose data can be aggregated over\n",
    "#file_list = ['indene_full_data_centroided_corrected']\n",
    "file_list = ['fluorene_full_data_centroided_corrected']\n",
    "#file_list = ['CPP_full_data_centroided_corrected']\n",
    "df_list = []\n",
    "\n",
    "for f in zip(file_list):\n",
    "    print(f[0])\n",
    "    print('Opening file: '+f[0])\n",
    "    data = np.load(f\"{f[0]}.npy\", mmap_mode='r')\n",
    "    #df = pd.DataFrame(data, columns = ['Energy','x','y','ToF','tag_ID','delay']) # 2021 data\n",
    "    #df = pd.DataFrame(data, columns = ['x','y','ToF','tId','delay','tag_ID','Energy']) # 2023 on the fly\n",
    "    df = pd.DataFrame(data, columns =  ['Energy','tag_ID','x','y','ToF','size','spread','delay','m_z']) # indene centroided data 2023\n",
    "    df['tag_ID'] = df['tag_ID'] .astype(int)\n",
    "    print('# shots = '+str(len(np.unique(df['tag_ID']))))\n",
    "    print('# events = '+str(len(df)))\n",
    "    df_list.append(df)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. ToF-ToF covariance function\n",
    "\n",
    "# Imports and functions\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from numba import njit\n",
    "import h5py\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "@njit\n",
    "def reindex_shots(shot_list):\n",
    "    \n",
    "    for i, shot in enumerate(shot_list):\n",
    "        if shot == shot_list[i+1]: continue\n",
    "        if shot == shot_list[i+1]-1: continue \n",
    "        if shot != shot_list[i+1]-1:\n",
    "            shot_list[i+1:] -= (shot_list[i+1] - shot)\n",
    "            \n",
    "    return(shot_list)\n",
    "\n",
    "@njit\n",
    "def ToF_ToF_coincidence(Sij, frame_array_A, shot_list, min_ToF):\n",
    "    \n",
    "    no_A = frame_array_A.shape[0]\n",
    "    nshotsA, nendA = 0, 0\n",
    "    \n",
    "    for shot in shot_list:\n",
    "        \n",
    "        A_in_shot = False\n",
    "        \n",
    "        for test in range(nshotsA, no_A):\n",
    "            if (frame_array_A[test, 1] == shot):\n",
    "                nshotsA = test\n",
    "                A_in_shot = True\n",
    "                break\n",
    "                \n",
    "        if A_in_shot:\n",
    "            for test in range(nshotsA, no_A):\n",
    "                if frame_array_A[test, 1] > shot:\n",
    "                    nendA = test\n",
    "                    break\n",
    "                \n",
    "        if (nendA - nshotsA) > 1:\n",
    "            \n",
    "            for i in range(nshotsA, nendA):\n",
    "                A_index = frame_array_A[i, 0] - min_ToF -1\n",
    "                \n",
    "                for j in range(nshotsA, nendA):\n",
    "                        B_index = frame_array_A[j, 0] - min_ToF - 1\n",
    "                        \n",
    "                        Sij[A_index, B_index] += 1\n",
    "\n",
    "    return(Sij)\n",
    "\n",
    "def ToF_ToF_covariance(event_df, min_ToF, max_ToF):\n",
    "\n",
    "    df_filt = (event_df[(event_df['ToF'] >= min_ToF) & (event_df['ToF'] <= max_ToF)]).copy()\n",
    "    df_filt['ToF'] = (df_filt['ToF'] + 0.5).astype('int64')\n",
    "    event_array = np.array(df_filt[['ToF','tag_ID']])\n",
    "\n",
    "    shot_list = np.unique(event_array[:, 1])\n",
    "    n_shots = len(shot_list)\n",
    "\n",
    "    # Sij\n",
    "    \n",
    "    ToF_range = int(max_ToF - min_ToF)\n",
    "    Sij = np.zeros((ToF_range, ToF_range))\n",
    "    Sij = ToF_ToF_coincidence(Sij, event_array, shot_list, min_ToF)\n",
    "    Sij /= n_shots\n",
    "    \n",
    "    #SiSj\n",
    "    \n",
    "    unique, counts = np.unique(event_array[:, 0], return_counts = True)\n",
    "    ToF_array = np.zeros((ToF_range))\n",
    "    for count, unique in zip(counts, unique):\n",
    "        ToF_array[unique - min_ToF - 1] += count\n",
    "    ToF_array /= n_shots\n",
    "    SiSj = np.outer(ToF_array, ToF_array)\n",
    "    \n",
    "    return(Sij - SiSj, Sij, SiSj)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 4. calculate tof tof cov; contingent covariance adaptation coded by JHM\n",
    "\n",
    "covar_list = []\n",
    "\n",
    "covar_contingent_store = []\n",
    "\n",
    "number_of_bins = 5 # for contingent covariance (in reality, number of bins is one minus from this value) (JHM)\n",
    "\n",
    "for df in zip(df_list): # looping over each run number to sort energy bin stuff out\n",
    "        \n",
    "    df = df[0].sort_values(by=['Energy']) # load dataframe in ascending energy value\n",
    "    df_length = df.shape[0] # number of rows in total dataframe\n",
    "\n",
    "    min_energy = df['Energy'].min()\n",
    "    max_energy = df['Energy'].max()\n",
    "\n",
    "    FEL_energy_bins = []\n",
    "\n",
    "    index_range = np.arange(0, df_length, df_length/number_of_bins)\n",
    "    index_range_int = []\n",
    "\n",
    "    for a in range(len(index_range)): # need to make all values integers\n",
    "        index_range_int.append(int(index_range[a]))\n",
    "\n",
    "    print(f\"Integer index range: {index_range_int}\")\n",
    "\n",
    "    for index in index_range_int:\n",
    "        indexed_energy = df['Energy'].iloc[index]\n",
    "        FEL_energy_bins.append(indexed_energy)\n",
    "\n",
    "    print(f\"FEL energy bin values: {FEL_energy_bins}\")\n",
    "    \n",
    "for i, df in enumerate(zip(df_list)):\n",
    "    df = df[0]\n",
    "\n",
    "    print('Opening file: '+str(i))\n",
    "    count = 1\n",
    "    \n",
    "    for i in range(len(FEL_energy_bins)- 1):\n",
    "        \n",
    "        FEL_lower = FEL_energy_bins[i]\n",
    "        FEL_higher = FEL_energy_bins[i+1]\n",
    "        \n",
    "        FEL_filtered_df = df[(df['Energy'] >= FEL_lower) & (df['Energy'] <= FEL_higher)]\n",
    "        #print(FEL_filtered_df)\n",
    "        \n",
    "        #min_ToF, max_ToF = 1000, 1350 for triphenylene\n",
    "        \n",
    "        #min_ToF, max_ToF = 1550, 1800 # for indene; 2023 beamtime data\n",
    "        min_ToF, max_ToF = 1500, 1900 # for fluorene; 2023 beamtime data\n",
    "        \n",
    "        ToF_range = max_ToF - min_ToF\n",
    "        covar_sum_2 = np.zeros((ToF_range, ToF_range))\n",
    "        sij_sum_2 = np.zeros((ToF_range, ToF_range))\n",
    "        sisj_sum_2 = np.zeros((ToF_range, ToF_range))\n",
    "        start_time = time.time()\n",
    "\n",
    "        covar,Sij,SiSj = ToF_ToF_covariance(df, min_ToF, max_ToF)\n",
    "        print('Calculated covariance for bin %s at %s seconds'  % (count, round((time.time() - start_time), 1)))\n",
    "        covar_sum_2 += covar\n",
    "        sij_sum_2 += Sij\n",
    "        sisj_sum_2 += SiSj\n",
    "\n",
    "        covar_contingent_store.append(covar_sum_2)\n",
    "        count += 1\n",
    "    \n",
    "    covar_list.append(sum(covar_contingent_store))\n",
    "\n",
    "covar = sum(covar_list)\n",
    "print('Done!')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. plotting tof tof covariance\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(10,10))\n",
    "shw = ax.imshow(covar, cmap='inferno', origin='lower',vmin=0, vmax=1.5*np.max(covar)/50)\n",
    "ax.set_xlim(0,(max_ToF - min_ToF))\n",
    "ax.set_ylim(0,(max_ToF - min_ToF))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. TOF-TOF covariance plot but with TOF spectra on axes (JHM)\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "# TOF spectrum plotting\n",
    "tof_appended = []\n",
    "for df,file in zip(df_list,file_list):\n",
    "    print('Opening file: '+str(file[0]))\n",
    "    #df = df[(df['ToF']>1500) & (df['ToF']<1900)]\n",
    "    tof = df.groupby(['ToF']).size().reset_index(name='intensity')\n",
    "    tof_times_list = tof['ToF'].to_list()\n",
    "    tof_appended.append(tof)\n",
    "\n",
    "list_of_tof_intensities = []\n",
    "\n",
    "for tof_frame in zip(tof_appended):\n",
    "    tof_frame = tof_frame[0]\n",
    "    tof_intensity = tof_frame['intensity'].to_list()\n",
    "    list_of_tof_intensities.append(tof_intensity)\n",
    "\n",
    "total_summed_intensities = [sum(i) for i in zip(*list_of_tof_intensities)]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "plt.plot(tof_times_list,total_summed_intensities)\n",
    "\n",
    "ax.set_xlim(1550,1800)\n",
    "ax.grid(which='major')\n",
    "ax.grid(which='minor')\n",
    "ax.minorticks_on()\n",
    "plt.xlabel('Time-of-flight / arb. units', fontsize=16)\n",
    "plt.ylabel('Intensity / arb. units', fontsize=16)\n",
    "plt.title('Total ToF spectrum')\n",
    "#fig.savefig('triphenylene_total_tof.png')\n",
    "\n",
    "tof_times_list = [x-min_ToF for x in tof_times_list]\n",
    "\n",
    "# Plotting \n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "gs = fig.add_gridspec(2, 2,  width_ratios=(3, 1), height_ratios=(1, 3), left=0.1, right=0.9, bottom=0.1, top=0.9, wspace=0, hspace=0)\n",
    "ax = fig.add_subplot(gs[1, 0])\n",
    "\n",
    "ax_x = fig.add_subplot(gs[0, 0], sharex=ax) # TOF plot (top row)\n",
    "ax_y = fig.add_subplot(gs[1, 1], sharey=ax) # TOF plot (column)\n",
    "\n",
    "ax_x.plot(tof_times_list,total_summed_intensities, color = 'purple')\n",
    "ax_y.plot(total_summed_intensities, tof_times_list, color = 'purple')\n",
    "    \n",
    "#ax.set_xlim(0,300)\n",
    "ax_x.grid(which='major')\n",
    "ax_x.grid(which='minor', linewidth=0.3)\n",
    "ax_x.minorticks_on()\n",
    "ax_y.grid(which='major')\n",
    "ax_y.grid(which='minor', linewidth=0.3)\n",
    "ax_y.minorticks_on()\n",
    "ax_x.tick_params(axis=\"x\",direction=\"out\", pad=5)\n",
    "ax_y.tick_params(axis=\"y\",direction=\"out\", pad=5)\n",
    "ax.set_xlabel('Time-of-flight / a.u. ', fontsize=14,labelpad=15)\n",
    "ax.set_ylabel('Time-of-flight / a.u. ', fontsize=14,labelpad=15)\n",
    "ax_x.set_ylabel('Intensity / a.u. ', fontsize=14,labelpad=15)\n",
    "ax_y.set_xlabel('Intensity / a.u. ', fontsize=14,labelpad=15)      \n",
    "plt.setp(ax_x.get_xticklabels(), visible=False)\n",
    "plt.setp(ax_y.get_yticklabels(), visible=False)\n",
    "        \n",
    "ax.grid(which='major')\n",
    "ax.grid(which='minor', linewidth=0.3)\n",
    "ax.minorticks_on()\n",
    "        \n",
    "picture = ax.imshow(covar, interpolation='nearest', cmap='inferno', vmin=0, vmax=np.max(covar)/50) # edit vmax as necessary\n",
    "\n",
    "# colorbar formatting\n",
    "# fig.subplots_adjust(right=0.8)\n",
    "# cbar_ax = fig.add_axes([1, 0.15, 0.05, 0.7])\n",
    "# fig.colorbar(picture, cax=cbar_ax)\n",
    "# cbar_ax.set_ylabel('Covariance / a.u.', fontsize = 14, rotation = 270, labelpad=25)\n",
    "\n",
    "divider = make_axes_locatable(ax_y)\n",
    "cax = divider.append_axes(\"right\", size=\"10%\", pad=0.10)\n",
    "\n",
    "fig.colorbar(picture, cax=cax, pad = 0.1)\n",
    "cax.set_ylabel('Covariance / a.u.', fontsize = 14, rotation = 270, labelpad=25)\n",
    "\n",
    "#directory=os.chdir(r\"/home/merrickj/Documents/indene_ion_figs_and_cov_plots\")\n",
    "#fig.savefig('TOF_TOF_covariance_indene',bbox_inches=\"tight\")\n",
    "\n",
    "directory=os.chdir(r\"/home/merrickj/Documents/fluorene_ion_figs_and_cov_plots\")\n",
    "fig.savefig('TOF_TOF_covariance_fluorene',bbox_inches=\"tight\")\n",
    "\n",
    "# directory=os.chdir(r\"/home/merrickj/Documents/CPP_ion_figs_and_cov_plots\")\n",
    "# fig.savefig('TOF_TOF_covariance_CPP',bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

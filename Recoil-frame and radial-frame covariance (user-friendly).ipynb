{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### User-friendly recoil-frame and radial-frame covariance code ###\n",
    "\n",
    "# This code is intended to contain the radial-frame covariance adaptation of the pre-existing recoil-frame covariance code,\n",
    "# where the code is intended to run on either simulated or real PImMS data (specified by user input). Below is a draft of how\n",
    "# each section is intended to run:\n",
    "\n",
    "# 1: Functions and imports, and defining the 'beautify' function (for making graphs look pretty) and the 'create_image' function\n",
    "#    for producing centred ion-images in a given time-interval.\n",
    "\n",
    "# 2. Define pre-existing recoil-frame covariance function with radial-frame adaptation\n",
    "\n",
    "# 3. Loading data (according to whether user wants simulated or real data to be used):\n",
    "#     - If simulated data, load the _pixelated.csv file directly and save as df.\n",
    "#     - If real data, access .bin file and convert to df (using procedure in \"on the fly ion images...\" Python script).\n",
    "\n",
    "# 4. Plotting TOF spectrum (possible adaptation for run-averaged TOF spectrum for real-data).\n",
    "\n",
    "# 5. Calibration of TOF spectrum to convert from TOF-domain to m/z domain (user input for predicted m/z values and corresponding\n",
    "#    TOF values from previous TOF spectrum assignment) via linear-regression. Add extra column to df for m/z values using linear\n",
    "#    regression parameters obtained, and plot m/z-domain spectrum.\n",
    "\n",
    "# 6. Plot raw ion-images for specified ions of choice (supplied as user input). May need to change centre values for certain\n",
    "#    ions.\n",
    "\n",
    "# 7. Perform Abel-inversion on raw (centred) ion-images, and obtain radial disributions of ions.\n",
    "\n",
    "# 8. Compress data\n",
    "\n",
    "# 9. Calculating ion covariances, calling the main covariance function defined in (2).\n",
    "\n",
    "# 10. Plotting the recoil-frame covariance maps.\n",
    "\n",
    "# 11. Plotting the radial-frame covariance maps.\n",
    "\n",
    "# 12. Plotting final radial-frame covariance map with radial distribution functions on axes.\n",
    "\n",
    "# 13. Scaling the radial covariance matrices relative to the maximum matrix entry (across all radial matrices) and re-plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: Functions and imports, and defining the beautify function (for making graphs look pretty) and the create_image function\n",
    "#    for producing centred ion-images in a given time-interval.\n",
    "#    Adapted from: \"Recoil-frame covariance (for Part IIs, 220930).ipynb\"\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import matplotlib.patches as patches\n",
    "import multiprocessing as mp\n",
    "from scipy import ndimage\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import gc # garbage collector - helps with data storage \n",
    "\n",
    "# Function to make images look pretty\n",
    "def beautify(ax):\n",
    "    ax.tick_params(axis = 'x', labelsize = 10)\n",
    "    ax.tick_params(axis = 'y', labelsize = 10)\n",
    "    ax.tick_params('both', length = 3, width = 1)\n",
    "    ax.spines['bottom'].set_linewidth(1)\n",
    "    ax.spines['top'].set_linewidth(1)\n",
    "    ax.spines['right'].set_linewidth(1)\n",
    "    ax.spines['left'].set_linewidth(1)\n",
    "\n",
    "# Function for producing centred ion-images within a specified time-interval and a specified ion-image centre\n",
    "def create_image(df, centre, ti = 0, tf = 0):\n",
    "    if (ti & tf):\n",
    "        df = df[(df['ToF'] >= ti) & (df['ToF'] <= tf)] # sets time-interval for image (replace ToF with t for sim. data)\n",
    "    image = np.zeros((324, 324)) # sets initial array for image\n",
    "    xy = df.groupby(['x', 'y']).size().reset_index(name = 'intensity') # computes the intensity for each xy coordinate\n",
    "    results = (np.array(xy).astype(int))\n",
    "    cx = 162 - centre[0] # shift in x axis for centred image (by manually defined centre in function input)\n",
    "    cy = 162 - centre[1] # shift in y axis for centred image (by manually defined centre in function input)\n",
    "    for a,b,c in results: # assigns the intensity (c) to each coordinate in the image (from specified results input)\n",
    "        if 0 <= (b + cx) < 324:\n",
    "            if 0 <= (a + cy) < 324:\n",
    "                image[b + cx, a + cy] = c\n",
    "        \n",
    "    return(image) # returns centred image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define pre-existing recoil-frame covariance function with radial-frame adaptation.\n",
    "#    Adapted from: \"Recoil-frame covariance (for Part IIs, 220930).ipynb\"\n",
    "\n",
    "from numba import jit \n",
    "\n",
    "@jit(nopython = True) # think this is just a way to make the calculations run quicker / in parallel(?) once function is called\n",
    "def recoil_frame_Sij_2(array_A, array_B, shot_array, pixels, mean_A, mean_B): # for norm; array_A and array_B are df_A and df_B\n",
    "    \n",
    "    Sij_array = np.zeros((pixels, pixels), dtype = np.float64) # setting up 2D recoil-frame covariance array\n",
    "    radial_Sij_array = np.zeros((int(pixels/2), int(pixels/2))) # setting up 2D radial-radial covariance array\n",
    "\n",
    "   \n",
    "    no_A = array_A.shape[0] # array_A = df_A; shape returns no of shots with A in (+ dummy shot)\n",
    "    no_B = array_B.shape[0] # array_B = df_B; shape returns no of shots with B in (+ dummy shot)\n",
    "#     print(\"array a recoil_frame_Sij_2\")\n",
    "#     print(array_A) # r, theta, shot\n",
    "#     print(\"array b recoil_frame_Sij_2\")\n",
    "#     print(array_B) # r, theta, shot\n",
    "    #print(\"recoil_frame_Sij_2 (no_A no_B)\")\n",
    "    #print(no_A, no_B)\n",
    "    \n",
    "    nshotsA, nshotsB = 0, 0\n",
    "    nendA, nendB = 0, 0\n",
    "#     print(shot_array)\n",
    "    for shot in shot_array: # loop over all shots in shot array\n",
    "        # print('Shot:'+str(shot))\n",
    "        A_in_shot, B_in_shot = False, False\n",
    "        \n",
    "        for test in range(nshotsA, no_A): # looping over shots with A in them; marking whether A is in shot or not\n",
    "            if (array_A[test, 2] == shot):\n",
    "                nshotsA = test\n",
    "#                 print('A Shots:'+str(nshotsA))\n",
    "                A_in_shot = True\n",
    "                break\n",
    "        \n",
    "        if A_in_shot:\n",
    "            for test in range(nshotsA, no_A):\n",
    "                if array_A[test, 2] > shot:\n",
    "                    nendA = test\n",
    "#                     print('A End:'+str(nendA))\n",
    "                    break\n",
    "\n",
    "            for test in range(nshotsB, no_B):\n",
    "                if (array_B[test, 2] == shot):\n",
    "                    nshotsB = test\n",
    "#                     print('B Shots:'+str(nshotsB))\n",
    "                    B_in_shot = True\n",
    "                    break\n",
    "        \n",
    "        if B_in_shot:\n",
    "            for test in range(nshotsB, no_B):\n",
    "                if array_B[test, 2] > shot:\n",
    "                    nendB = test\n",
    "#                     print('B End:'+str(nendB))\n",
    "                    break\n",
    "        \n",
    "        if A_in_shot & B_in_shot:\n",
    "#             print('A and B found')\n",
    "#             print(nendA, nshotsA)\n",
    "            n_A_ions = (nendA - nshotsA)\n",
    "            n_B_ions = (nendB - nshotsB)\n",
    "#             print('A ions:', n_A_ions)\n",
    "#             print('B ions:', n_B_ions)\n",
    "            for i in range(nshotsA, nendA):\n",
    "                rad_A = array_A[i, 0]\n",
    "                theta_A = array_A[i, 1]\n",
    "#                 print(rad_A, theta_A)\n",
    "\n",
    "                for j in range(nshotsB, nendB):\n",
    "                    rad_B = array_B[j, 0]\n",
    "                    theta_B = array_B[j, 1]\n",
    "                \n",
    "                    # need to convert radii to integers\n",
    "                    rad_A_int = int(round(rad_A))\n",
    "                    rad_B_int = int(round(rad_B))\n",
    "                    #print(rad_A_int, rad_B_int)\n",
    "\n",
    "                    theta_rel = theta_B - theta_A # relative angle between two hits\n",
    "                    \n",
    "                    if (0 < rad_A_int < pixels/2) and (0 < rad_B_int < pixels/2): # if hit is within image array\n",
    "                        radial_Sij_array[rad_A_int, rad_B_int] += mean_A/n_A_ions\n",
    "                    \n",
    "                    # correction to make sure all relative angles are between 0 and 2*pi\n",
    "                    if theta_rel>2*np.pi:\n",
    "                        theta_rel=theta_rel-2*np.pi\n",
    "                    elif theta_rel<0:\n",
    "                        theta_rel=theta_rel+2*np.pi\n",
    "\n",
    "                    x = int(round(rad_B*np.cos(theta_rel) + pixels/2))\n",
    "                    y = int(round(rad_B*np.sin(theta_rel) + pixels/2))\n",
    "#                     print(x,y)\n",
    "\n",
    "                    if (0 < x < pixels) and (0 < y < pixels): # if hit is within the image array\n",
    "                        Sij_array[y-1, x-1] += mean_A/n_A_ions\n",
    "#                         Sij_array[y-1, x-1] += mean_B\n",
    "#                         Sij_array[y-1, x-1] += mean_B/n_B_ions\n",
    "#                         Sij_array[y-1, x-1] += int(1)/n_A_ions\n",
    "#                         Sij_array[y-1, x-1] += int(1)\n",
    "#                         print(mean_A,n_A_ions)\n",
    "#                         print('Sij_array:')\n",
    "#                         print(np.unique(Sij_array))\n",
    "    \n",
    "    return(Sij_array, radial_Sij_array)\n",
    "\n",
    "@jit(nopython = True)\n",
    "def recoil_frame_SiSj(reduced_array_A, reduced_array_B, pixels): # for not norm; reduced_array_A = A_array_SiSj (and likewise for B)\n",
    "    \n",
    "    SiSj_array = np.zeros((pixels, pixels), dtype = np.int64)\n",
    "    radial_SiSj_array = np.zeros((int(pixels/2), int(pixels/2)))\n",
    "    \n",
    "    no_A = reduced_array_A.shape[0]\n",
    "    no_B = reduced_array_B.shape[0]\n",
    "#     print(no_A)\n",
    "#     print(no_B)\n",
    "    \n",
    "    for i in range(no_A): \n",
    "#         print(i)\n",
    "        rad_A = reduced_array_A[i, 0]\n",
    "        theta_A = reduced_array_A[i, 1]\n",
    "        count_A = reduced_array_A[i, 2]\n",
    "\n",
    "        for j in range(no_B):\n",
    "#             print(i, j)\n",
    "            rad_B = reduced_array_B[j, 0]\n",
    "            theta_B = reduced_array_B[j, 1]\n",
    "            count_B = reduced_array_B[j, 2]\n",
    "            \n",
    "#             if rad_A and rad_B:\n",
    "            if 3:\n",
    "        \n",
    "                theta_rel = theta_B - theta_A\n",
    "                if theta_rel > 2*np.pi:\n",
    "                    theta_rel = theta_rel - 2*np.pi\n",
    "                elif theta_rel < 0:\n",
    "                    theta_rel = theta_rel + 2*np.pi\n",
    "\n",
    "                x = int(round(rad_B*np.cos(theta_rel) + pixels/2))\n",
    "                y = int(round(rad_B*np.sin(theta_rel) + pixels/2))\n",
    "                \n",
    "                # need to convert radii to integers\n",
    "                rad_A_int = int(round(rad_A))\n",
    "                rad_B_int = int(round(rad_B))\n",
    "                \n",
    "#                 print(x,y, theta_rel)\n",
    "#                 print(count_A, count_B)\n",
    "                if (0 < x < pixels) and (0 < y < pixels): # if hit is within the image array\n",
    "                    SiSj_array[y-1, x-1] += int(count_A*count_B)\n",
    "                if (0 < rad_A_int < pixels/2) and (0 < rad_B_int < pixels/2):\n",
    "                    radial_SiSj_array[rad_A_int, rad_B_int] += int(count_A*count_B)\n",
    "#                     print(np.unique(SiSj_array))\n",
    "    \n",
    "    return(SiSj_array, radial_SiSj_array)\n",
    "\n",
    "def two_fold_recoil_frame_covariance(df_A, df_B, shot_list, pixels, norm = False): # MAIN COVARIANCE FUNCTION \n",
    "\n",
    "    n_shots = len(shot_list)-1 # number of shots (in this case, 10000)\n",
    "#     print('Shot length:'+str(n_shots))\n",
    "    \n",
    "######## Sij = <xy> ################################################################################\n",
    "    \n",
    "    start_time = time.time() # just starts a timer\n",
    "    \n",
    "    A_array = df_A[['r', 'theta', 'tId']].values # r, theta, shot no array from df_A\n",
    "    B_array = df_B[['r', 'theta', 'tId']].values # r, theta, shot no array from df_B\n",
    "    \n",
    "    #print(\"covariance A_array\")\n",
    "    #print(A_array)\n",
    "    #print(\"covariance B_array\")\n",
    "    #print(B_array)\n",
    "    \n",
    "    shot_array_A = np.unique(df_A.tId) # numpy array of unique shot numbers containing A\n",
    "    shot_array_B = np.unique(df_B.tId) # numpy array of unique shot numbers containing B\n",
    "    \n",
    "    shot_array = np.intersect1d(shot_array_A, shot_array_B) # array of shot numbers containing both ion A and ion B\n",
    "    shot_array = shot_array.astype('int64')\n",
    "    #print(\"shot_array covariance\")\n",
    "    #print(shot_array)\n",
    "\n",
    "    A_array = np.vstack([A_array, [-1000,-1000,len(shot_list)]]) # Add dummy shots to fix counting issue\n",
    "    B_array = np.vstack([B_array, [-1000,-1000,len(shot_list)]])\n",
    "    #print(\"a array new\")\n",
    "    #print(A_array.shape)\n",
    "    #print(\"b array new\")\n",
    "    #print(B_array.shape)    \n",
    "    \n",
    "    #print(\"len df_A\")\n",
    "    #print(len(df_A))\n",
    "    #print(\"len df_B\")\n",
    "    #print(len(df_B))\n",
    "    \n",
    "    # what does norm mean? A: normalisation\n",
    "    if norm:\n",
    "        mean_A = (len(df_A))/(n_shots)   # likelihood of ion A appearing in a given shot\n",
    "        mean_B = (len(df_B))/(n_shots)   # likelihood of ion B appearing in a given shot      \n",
    "#         print('Length A: ', len(df_A))\n",
    "#         print('Mean A: ', mean_A) # likelihood of ion A appearing in a given shot\n",
    "#         print('Length B: ', len(df_B))\n",
    "#         print('Mean B: ', mean_B) # likelihood of ion B appearing in a given shot\n",
    "#         print(len(df_A)-1,n_shots,mean_A)\n",
    "        Sij, Sij_rad = recoil_frame_Sij_2(A_array, B_array, shot_array, pixels, mean_A, mean_B) ### function 1 to look at\n",
    "#         print(\"test test test for if norm\")\n",
    "        Sij = Sij.astype('float64')\n",
    "        Sij_rad = Sij_rad.astype('float64')\n",
    "#         print(np.unique(Sij))\n",
    "        Sij /= float(n_shots) # divide by total number of shots\n",
    "        Sij_rad /= float(n_shots)\n",
    "#         print(np.unique(Sij), n_shots)\n",
    "#         print(Sij)\n",
    "\n",
    "    else: # currently not in use ***********\n",
    "        mean_A = (len(df_A)-1)/n_shots\n",
    "#         print('Mean A', mean_A)\n",
    "#         print(A_array, B_array)\n",
    "        Sij = recoil_frame_Sij_1(A_array, B_array, shot_array, pixels, mean_A) ### function 2 to look at \n",
    "        Sij = Sij.astype('float64')\n",
    "#         print(np.unique(Sij))\n",
    "        Sij /= float(n_shots)\n",
    "#         print(np.unique(Sij), n_shots)\n",
    "        \n",
    "    print(\"Calculating Sij took %s seconds\" % round((time.time() - start_time), 1)) # times how long it took to calculate Sij\n",
    "    \n",
    "########### SiSj = <x><y> ################################################################################\n",
    "    \n",
    "    start_time = time.time()\n",
    "        \n",
    "    df_A_count_series = df_A.groupby(['r', 'theta']).size()\n",
    "#     print(\"df_A_count_series\")\n",
    "#     print(df_A_count_series)\n",
    "#     print(df_A_count_series.shape)\n",
    "    df_A_count_df_SiSj = df_A_count_series.to_frame(name = 'size').reset_index()\n",
    "#     print(\"df_A_count_df_SiSj\")\n",
    "#     print(df_A_count_df_SiSj)\n",
    "#     print(df_A_count_df_SiSj.shape)\n",
    "\n",
    "    df_B_count_series = df_B.groupby(['r', 'theta']).size()\n",
    "    df_B_count_df_SiSj = df_B_count_series.to_frame(name = 'size').reset_index()\n",
    "#     print(df_B_count_df_SiSj)\n",
    "    \n",
    "    A_array_SiSj = df_A_count_df_SiSj[['r', 'theta', 'size']].values # just converts from df to numpy array\n",
    "#     print(\"A_array_SiSj\")\n",
    "#     print(A_array_SiSj)\n",
    "    B_array_SiSj = df_B_count_df_SiSj[['r', 'theta', 'size']].values # just converts from df to numpy array\n",
    "#     print(\"B_array_SiSj\")\n",
    "#     print(B_array_SiSj)\n",
    "    \n",
    "#     print(A_array_SiSj, B_array_SiSj)    \n",
    "    SiSj, SiSj_rad = recoil_frame_SiSj(A_array_SiSj, B_array_SiSj, pixels) # calculates <SiSj>\n",
    "#     print(SiSj)\n",
    "    SiSj = SiSj.astype('float64')\n",
    "    SiSj_rad = SiSj_rad.astype('float64')\n",
    "#     print(np.unique(SiSj))\n",
    "    SiSj /= (n_shots)**2\n",
    "    SiSj_rad /= (n_shots)**2\n",
    "#     SiSj /= (n_shots-1)**2\n",
    "#     print(np.unique(SiSj))\n",
    "#     SiSj /= mean_A\n",
    "    \n",
    "    \n",
    "    print(\"Calculating SiSj took %s seconds\" % round((time.time()-start_time),1))\n",
    "    \n",
    "    return(Sij, SiSj, Sij_rad, SiSj_rad)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 3. Loading data (according to whether user wants simulated or real data to be used):\n",
    "#     - If simulated data, load the _pixelated.csv file (produced from CEI simulation script) directly and save as df.\n",
    "#     - If real data, access .bin file and convert to df (using procedure in \"on the fly ion images...\" Python script).\n",
    "#    Adapted from: \"on the fly ion images + delay + rdf NOT CENTROIDED v6 EMW C4H4Se.ipynb\"\n",
    "\n",
    "file_type = int(input(\"Choose whether you would like to analyse simulated data ('0') or real data ('1'): \"))\n",
    "    \n",
    "# If wanting to analyse simulated data \n",
    "if file_type == 0:\n",
    "    \n",
    "    df_list = []\n",
    "    \n",
    "    df = str(input(\"Enter the _pixelated.csv file name: \"))\n",
    "    directory=os.chdir(r\"/home/merrickj/Documents/simulated_data_figs\")\n",
    "    df = pd.read_csv(f\"{df}\", names=['x','y','ToF','tId'], usecols=[0,1,2,3], header=0)\n",
    "    print(df)\n",
    "    \n",
    "    df_list.append(df)\n",
    "    \n",
    "# If wanting to analyse real data\n",
    "elif file_type == 1:\n",
    "    \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import math\n",
    "    import os\n",
    "    import re\n",
    "    import time\n",
    "    from numpy import exp, loadtxt, pi, sqrt\n",
    "    import matplotlib.cm as cm\n",
    "    import gc\n",
    "   \n",
    "    pd.set_option('display.max_rows', 4096) # Controls number of lines displayed (PImMS maximum = 4096 timebins)\n",
    "    \n",
    "    #directory=os.chdir(r\"/home/merrickj/Documents/indene_filtered_data_for_covariance\")\n",
    "    #directory=os.chdir(r\"/home/merrickj/Documents/fluorene_filtered_data_for_covariance\")\n",
    "    #directory=os.chdir(r\"/home/merrickj/Documents/CPP_filtered_data_for_covariance\")\n",
    "    directory=os.chdir(r\"/home/merrickj/Documents/fluorene_2018_all\")\n",
    "\n",
    "    #file_list = ['038','039','040','041','042','043','044'] # run number; adapt to supply an array of run numbers whose data can be aggregated over\n",
    "    #file_list = ['222','223','224','226','227'] # run numbers for indene (2023) beamtime data\n",
    "    \n",
    "    #file_list = ['indene_full_data_centroided_corrected']\n",
    "    #file_list = ['fluorene_full_data_centroided_corrected']\n",
    "    #file_list = ['CPP_full_data_centroided_corrected']\n",
    "    file_list = ['fluorene_full_data_centroided_uncorrected']\n",
    "    \n",
    "    df_list = []\n",
    "    \n",
    "    for f in zip(file_list):\n",
    "        print(f[0])\n",
    "        print('Opening file: '+f[0])\n",
    "        data = np.load(f\"{f[0]}.npy\", mmap_mode='r') # loads centroided and filtered numpy array\n",
    "        #df = pd.DataFrame(data, columns = ['Energy','tId','x','y','ToF','size','spread','delay','m_z']) # for centroided\n",
    "        df = pd.DataFrame(data, columns = ['x','y','ToF','tId','delay','size','spread']) # for centroided 2018\n",
    "        print(df)\n",
    "        df_list.append(df)\n",
    "        \n",
    "        del data\n",
    "        gc.collect()\n",
    "    \n",
    "else:\n",
    "    sys.exit('Invalid data-type supplied.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4a. Plotting run-separated TOF spectrum. This should work - if memory issues arise, just restart the kernel.\n",
    "#    Adapted from: \"on the fly ion images + delay + rdf NOT CENTROIDED v6 EMW C4H4Se.ipynb\"\n",
    "\n",
    "# Simulated data\n",
    "if file_type == 0:\n",
    "    fig, ax = plt.subplots(figsize=(15, 6))\n",
    "    #beautify(ax)\n",
    "    tof = df.groupby(['ToF']).size().reset_index(name='intensity')\n",
    "    plt.bar(tof.ToF,tof.intensity, width = 0.1)\n",
    "    plt.xlabel('Time-of-flight / a.u.', fontsize=16)\n",
    "    plt.tick_params(axis='x', labelsize=12)\n",
    "    plt.ylabel('Intensity / a.u.', fontsize=16)\n",
    "    plt.tick_params(axis='y', labelsize=12)\n",
    "    ax.grid(which='major')\n",
    "    ax.grid(which='minor')\n",
    "    ax.minorticks_on()\n",
    "    plt.title('ToF spectrum - ethene (simulated CEI data)', fontsize = 16)\n",
    "    ax.set_xlim(0,15)\n",
    "    fig.savefig('ethene_tof_spectrum.png')\n",
    "    plt.show()\n",
    "    \n",
    "# Real data - seperated by run number, and then summed over all run numbers\n",
    "if file_type == 1:\n",
    "    fig, ax = plt.subplots(figsize=(15, 6))\n",
    "    beautify(ax)\n",
    "    plt.xlabel('Time-of-flight / a.u.', fontsize=12)\n",
    "    plt.tick_params(axis='x', labelsize=12)\n",
    "    plt.ylabel('Intensity / a.u.', fontsize=12)\n",
    "    plt.tick_params(axis='y', labelsize=12)\n",
    "    ax.set_xlim(2050,2500) # alter as necessary\n",
    "    ax.grid(which='major')\n",
    "    ax.grid(which='minor')\n",
    "    ax.minorticks_on()\n",
    "    tof_appended = []\n",
    "    for df,file in zip(df_list,file_list):\n",
    "        \n",
    "        #plt.title('Run-concatenated ToF spectrum - indene', fontsize = 16)\n",
    "        #plt.title('Run-concatenated ToF spectrum - fluorene', fontsize = 16)\n",
    "        #plt.title('Run-concatenated ToF spectrum - CPP', fontsize = 16)\n",
    "        plt.title('Run-concatenated ToF spectrum - fluorene (2018)', fontsize = 16)\n",
    "        \n",
    "        #df = df[(df['ToF']>1550) & (df['ToF']<1900)]\n",
    "        tof = df.groupby(['ToF']).size().reset_index(name='intensity')\n",
    "        tof_times_list = tof['ToF'].to_list()\n",
    "        #print(tof)\n",
    "        tof_appended.append(tof)\n",
    "        plt.plot(tof.ToF,tof.intensity,label=str(file), color = 'black')\n",
    "        #ax.legend(loc='upper right', fontsize=18)\n",
    "    plt.show()\n",
    "    \n",
    "    #directory=os.chdir(r\"/home/merrickj/Documents/indene_ion_figs_and_cov_plots\")\n",
    "    #fig.savefig('indene_concatenated_tof_spectrum.png')\n",
    "    \n",
    "    #directory=os.chdir(r\"/home/merrickj/Documents/fluorene_ion_figs_and_cov_plots\")\n",
    "    #fig.savefig('fluorene_concatenated_tof_spectrum.png')\n",
    "    \n",
    "    #directory=os.chdir(r\"/home/merrickj/Documents/CPP_ion_figs_and_cov_plots\")\n",
    "    fig.savefig('fluorene_2018_concatenated_tof_spectrum.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 6a. Plot raw ion-images for specified ions of choice (supplied as user input). May need to change centre values for certain\n",
    "#    ions.\n",
    "#    Adapted from: \"Recoil-frame covariance (for Part IIs, 220930).ipynb\"\n",
    "\n",
    "# for fluorene, 2018 data\n",
    "# pixels = 324\n",
    "# ion_list = ['C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11', 'C12']\n",
    "# ToF_list = [(2219,2221),(2249,2251),(2279,2281),(2304,2306),(2326,2328),(2349,2351),(2367,2369),(2392,2394),(2409,2411),(2425,2427),(2441,2443)]\n",
    "# centre_list = [(160,135),(160,130),(161,129),(160,125),(160,120),(160,115),(160,110),(159,109),(160,105),(160,102),(160,99)] # centres of ion images - fine-tune as necessary\n",
    "\n",
    "# for triphenylene, 2021 data\n",
    "#pixels = 324\n",
    "#ion_list = ['CH$^{2+}$','C$^{+}$','C$_{2}$H$_{2}^{+}$','C$_{3}$H$_{x}^{+}$','C$_{4}$H$_{x}^{+}$','C$_{5}$H$_{x}^{+}$','C$_{6}$H$_{x}^{+}$','C$_{7}$H$_{x}^{+}$','C$_{8}$H$_{x}^{+}$','C$_{9}$H$_{x}^{+}$']\n",
    "#ToF_list = [(1044,1046),(1061,1063),(1097,1099),(1119,1121),(1139,1141),(1156,1158),(1172,1174),(1187,1189),(1202,1204),(1216,1218)]\n",
    "#centre_list = [(165,162),(175,162),(178,162),(192,162),(195,162),(196,162),(198,162),(202,162),(205,162),(210,162)]\n",
    "\n",
    "# for fluorene, 2023 data (wrong)\n",
    "#pixels = 324\n",
    "#ion_list = ['C12(+)','C11(+)','C10(+)','C9(+)','C8(+)','C7(+)','C6(+)','C11(2+)','C5(+)','C9(2+)','C4(+)','C11(3+)','C3(+)','C9(3+)','C2(+)']\n",
    "#ToF_list = [(1824,1826),(1811,1813),(1800,1802),(1787,1789),(1772,1774),(1754,1756),(1737,1739),(1729,1731),(1711,1713),(1700,1702),(1691,1693),(1679,1681),(1671,1673),(1649,1651)]\n",
    "#centre_list = [(222,140),(220,140),(215,140),(215,140),(212,140),(205,140),(201,140),(200,140),(200,140),(195,140),(195,140),(191,140),(190,140),(185,140),(180,140)]\n",
    "#print(len(ion_list))\n",
    "#print(len(ToF_list))\n",
    "#print(len(centre_list))\n",
    "\n",
    "# pixels = 324\n",
    "# ToF_list = [(1613, 1616),(1617, 1621),(1631, 1634),(1643, 1646),(1650, 1652), (1657, 1662),(1662,1671),(1670, 1673), (1679,1683),(1688,1695),(1699,1705), (1708,1714), (1716,1723), (1725,1735),(1734,1741),(1743,1750), (1749,1755),(1756,1765),(1770,1776),(1783,1793), (1794,1803), (1810,1816),(1831,1841)]\n",
    "# ion_list = ['N(++)','O(++)','C2(++)','O(+)','water(+)','carbon_dioxide(++)','C2(+)','dinitrogen(+)','dioxygen(+)','C3(+)','carbon_dioxide(+)','C4(+)','PAH(+++)','C5(+)','C11(++)','C6(+)','PAH(++)','C7(+)','C8(+)','C9(+)','C10(+)','C11(+)','PAH-H(+)']\n",
    "# centre_list = [(162,162),(162,162),(182,140),(162,162),(162,162),(162,162),(188,140),(162,162),(162,162),(193,140),(162,162),(198,140),(203,140),(203,140),(203,140),(206,140),(206,140),(212,140),(215,140),(215,140),(217,140),(218,140),(225,140)]\n",
    "\n",
    "# for indene, 2023 data\n",
    "#ToF_list = [(1630,1634),(1665,1670),(1685,1697),(1700,1703),(1708,1718),(1720,1722),(1725,1735),(1740,1750),(1755,1765),(1785,1795)]\n",
    "#ion_list = ['C1','C2','C3','C7(2+)','C4','IND(2+)','C5','C6','C7','IND(+)']\n",
    "#centre_list = [(185,144),(190,144),(197,144),(199,144),(201,144),(202,144),(205,144),(208,144),(213,144),(217,144)] # change manually\n",
    "\n",
    "# for fluorene, 2023 data\n",
    "# ToF_list = [(1831,1840),(1820,1830),(1810,1818),(1798,1802),(1780,1792),(1770,1778),(1755,1765),(1750,1752),(1742,1749),(1735,1740),(1725,1733),(1720,1722),(1707,1715),(1699,1704),(1685,1698),(1662,1672),(1630,1633)]\n",
    "# ion_list = ['FLU(+)','C12(+)','C11(+)','C10(+)','C9(+)','C8(+)','C7(+)','FLU(++)','C6(+)','C11(++)','C5(+)','FLU(+++)/C9(++)','C4(+)','C3(+)','C7(++)/FLU(++++)','C2(+)','C1(+)']\n",
    "# centre_list = [(222,142),(221,142),(220,142),(217,142),(212,142),(210,142),(205,142),(205,142),(203,142),(201,142),(200,142),(198,142),(198,142),(195,142),(192,142),(189,142),(180,142)]\n",
    "\n",
    "# for CPP, 2023 data\n",
    "# ToF_list = [(1631,1636),(1665,1671),(1686,1694),(1701,1707),(1710,1715),(1718,1722),(1725,1733),(1736,1740),(1742,1749),(1752,1754),(1757,1765),(1766,1770),(1772,1778),(1780,1791),(1795,1805),(1806,1815),(1820,1828),(1830,1838),(1842,1850),(1851,1860),(1864,1869)]\n",
    "# ion_list = ['C1','C2','C3','CPP(4+)','C4','C9(2+)','C5','C11(2+)','C6','C13(2+)','C7','CPP(2+)','C8','C9','C10','C11','C12','C13','C14','CPP(+)','[CPP-dinitrogen](+)']\n",
    "# centre_list = [(191,145),(193,145),(195,145),(198,145),(203,145),(205,145),(205,145),(207,145),(210,145),(211,145),(213,145),(213,145),(215,145),(219,145),(222,145),(225,145),(227,145),(230,145),(231,145),(235,145),(238,145)]\n",
    "\n",
    "# for ethene, simulated data\n",
    "ToF_list = [(7,7),(14,14)]\n",
    "ion_list = ['$CH_{2}^{++}$','$CH_{2}^{+}$']\n",
    "centre_list = [(162,162),(162,162)]\n",
    "\n",
    "if len(ion_list) == len(centre_list) == len(ToF_list):\n",
    "    print(\"All arrays of same length.\")\n",
    "    \n",
    "# Simulated data\n",
    "if file_type == 0:\n",
    "    \n",
    "    list_of_total_images = []\n",
    "    \n",
    "    for i, (Ti, Tf) in enumerate(ToF_list):\n",
    "        ion = ion_list[i]\n",
    "        centre = centre_list[i]\n",
    "        fig, ax = plt.subplots(figsize = (7, 7))\n",
    "        image = create_image(df, centre, Ti, Tf)\n",
    "        list_of_total_images.append(image)\n",
    "        plt.ylabel('Pixels', fontsize=12, labelpad = 5)\n",
    "        plt.xlabel('Pixels', fontsize=12, labelpad = 5)\n",
    "        ax.imshow(image, interpolation='nearest',cmap = 'inferno', vmax = 0.5*np.max(image), vmin = 0, origin = 'lower')\n",
    "        ax.set_xlim(0,324)\n",
    "        ax.set_ylim(324,0) # Inverted to keep x,y directions the same as above\n",
    "        ax.text(0.04, 0.88, ion, transform = ax.transAxes, fontsize = 30, color = 'white')\n",
    "        ax.grid(which='major')\n",
    "        ax.grid(which='minor', linewidth=0.3)\n",
    "        ax.minorticks_on()\n",
    "        fig.savefig(f\"ion_image_{i}_ethene.png\")\n",
    "\n",
    "# Real data\n",
    "if file_type == 1:\n",
    "    \n",
    "    #directory=os.chdir(r\"/home/merrickj/Documents/indene_filtered_data_for_covariance\")\n",
    "    #directory=os.chdir(r\"/home/merrickj/Documents/fluorene_filtered_data_for_covariance\")\n",
    "    #directory=os.chdir(r\"/home/merrickj/Documents/CPP_filtered_data_for_covariance\")\n",
    "    \n",
    "    list_of_total_images = [] # for saving centroided data\n",
    "    \n",
    "    single_image = input(\"Do you wish to generate only single ion-images (y/n)?\")\n",
    "    \n",
    "    for i, (Ti, Tf) in enumerate(ToF_list):\n",
    "        image_store = []\n",
    "        ion = ion_list[i]\n",
    "        centre = centre_list[i]\n",
    "        \n",
    "        for df,file in zip(df_list,file_list):\n",
    "            \n",
    "            print('Opening file: '+str(file))\n",
    "            \n",
    "            if single_image in ['y', 'Y', 'yes', 'Yes', 'YES']: # if wanting to generate only single ion-images\n",
    "                \n",
    "                first_tId = df['tId'].iloc[0] # for plotting ion image just for one BID/tId to verify centroiding conditions\n",
    "                df_test = df[(df['tId'] == first_tId)]\n",
    "                print(f\"First tId for centroided data: {first_tId}\")\n",
    "                image = create_image(df_test, centre, Ti, Tf)\n",
    "                image_store.append(image)\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                image = create_image(df, centre, Ti, Tf)\n",
    "                image_store.append(image)\n",
    "            \n",
    "        total_image = sum(image_store)\n",
    "        print('Finished creating ion-image for ion: '+ ion)\n",
    "        list_of_total_images.append(total_image)\n",
    "        \n",
    "    print(\"*** Centroided ion-images now fully generated. ***\")\n",
    "    \n",
    "    uncentroided_comparison = input(\"Do you wish to generate ion-images for uncentroided data (y/n)?\")\n",
    "    \n",
    "    if uncentroided_comparison in ['y', 'Y', 'yes', 'Yes', 'YES']: # if wanting to generate ion-images for uncentroided data\n",
    "        \n",
    "        #uncentroided_data = np.load(\"indene_full_data_uncentroided_corrected.npy\",allow_pickle=True)\n",
    "        #uncentroided_data = np.load(\"fluorene_full_data_uncentroided_corrected.npy\",allow_pickle=True)\n",
    "        uncentroided_data = np.load(\"CPP_full_data_uncentroided_corrected.npy\",allow_pickle=True)\n",
    "        \n",
    "        uncentroided_data_df = pd.DataFrame(uncentroided_data, columns=['Energy','tId','x','y','ToF','counter_tagID','delay'])\n",
    "        print(\"Uncentroided concatenated dataframe:\")\n",
    "        print(uncentroided_data_df)\n",
    "        \n",
    "        list_of_total_images_uncentroided = []\n",
    "        \n",
    "        for i, (Ti, Tf) in enumerate(ToF_list):\n",
    "            \n",
    "            image_store = []\n",
    "            ion = ion_list[i]\n",
    "            centre = centre_list[i]\n",
    "            \n",
    "            if single_image in ['y', 'Y', 'yes', 'Yes', 'YES']: # if wanting to generate only single ion-images\n",
    "\n",
    "                first_tId = uncentroided_data_df['tId'].iloc[0] # for plotting ion image just for one BID/tId to verify centroiding conditions\n",
    "                print(f\"First tId for non-centroided data: {first_tId}\") # just to check that non-centroided and centroided plots involve the same tId's worth of data\n",
    "                df_test = df[(uncentroided_data_df['tId'] == first_tId)]\n",
    "                image = create_image(df_test, centre, Ti, Tf)\n",
    "                image_store.append(image)\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                image = create_image(uncentroided_data_df, centre, Ti, Tf)\n",
    "                image_store.append(image)\n",
    "\n",
    "            total_image = sum(image_store)\n",
    "            print('Finished creating ion-image for ion: '+ ion)\n",
    "            list_of_total_images_uncentroided.append(total_image)\n",
    "            \n",
    "        print(\"*** Non-centroided ion-images now also fully generated. ***\")\n",
    "        \n",
    "    else: # if not wanting to look at uncentroided data for comparison\n",
    "        \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 6b. Plot raw ion-images for specified ions of choice (supplied as user input). May need to change centre values for certain\n",
    "#    ions. This is a separate plotting function to the above to avoid having to run the create_image function several times\n",
    "#    (takes time for several fragments!) to allow for easy image editing once images are generated.\n",
    "#    Adapted from: \"Recoil-frame covariance (for Part IIs, 220930).ipynb\"\n",
    "\n",
    "#directory=os.chdir(r\"/home/merrickj/Documents/indene_ion_figs_and_cov_plots\")\n",
    "#directory=os.chdir(r\"/home/merrickj/Documents/fluorene_ion_figs_and_cov_plots\")\n",
    "#directory=os.chdir(r\"/home/merrickj/Documents/CPP_ion_figs_and_cov_plots\")\n",
    "\n",
    "crosshairs = False # if wanting to plot crosshairs to help with centring (taken from FLASH_compilation_2023_modified script)\n",
    "\n",
    "for i, (Ti, Tf) in enumerate(ToF_list):\n",
    "    ion = ion_list[i]\n",
    "    \n",
    "    total_image = list_of_total_images[i]\n",
    "    \n",
    "    if uncentroided_comparison in ['y', 'Y', 'yes', 'Yes', 'YES']: # if wanting to plot ion-images for uncentroided data; note that crosshairs aren't an option in this case as not needed\n",
    "        \n",
    "        total_image_uncentroided = list_of_total_images_uncentroided[i]\n",
    "        \n",
    "        fig, (ax1,ax2) = plt.subplots(nrows = 1, ncols = 2, figsize = (18,8)) # for plotting centroided and uncentroided side by side\n",
    "        \n",
    "        ax1.imshow(total_image, interpolation='nearest',cmap = 'inferno', vmax = 0.0008*np.max(total_image), vmin = 0, origin = 'lower')\n",
    "        ax1.set_xlim(0,324)\n",
    "        ax1.set_ylim(324,0) # Inverted to keep x,y directions the same as above\n",
    "        ax1.set_ylabel('Pixels', fontsize=12, labelpad = 5)\n",
    "        ax1.set_xlabel('Pixels', fontsize=12, labelpad = 5)\n",
    "        ax1.grid(which='major')\n",
    "        ax1.grid(which='minor', linewidth=0.3)\n",
    "        ax1.minorticks_on()\n",
    "        \n",
    "        ax2.imshow(total_image_uncentroided, interpolation='nearest',cmap = 'inferno', vmax = 0.0008*np.max(total_image_uncentroided), vmin = 0, origin = 'lower') # massively oversaturated to see ion hits more clearly in comparison\n",
    "        ax2.set_xlim(0,324)\n",
    "        ax2.set_ylim(324,0) # Inverted to keep x,y directions the same as above\n",
    "        ax2.set_ylabel('Pixels', fontsize=12, labelpad = 5)\n",
    "        ax2.set_xlabel('Pixels', fontsize=12, labelpad = 5)\n",
    "        ax2.grid(which='major')\n",
    "        ax2.grid(which='minor', linewidth=0.3)\n",
    "        ax2.minorticks_on()\n",
    "        \n",
    "        if single_image in ['y', 'Y', 'yes', 'Yes', 'YES']: # if wanting to generate only single ion-images\n",
    "            \n",
    "            ax1.set_title(f\"Single-shot ion-image for ion: {ion} (centroided)\", fontsize = 14, loc = 'center')\n",
    "            ax2.set_title(f\"Single-shot ion-image for ion: {ion} (non-centroided)\", fontsize = 14, loc = 'center')\n",
    "            \n",
    "            fig.savefig(f\"ion_image_comparison_{i}_single.png\")\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            ax1.set_title(f\"Total ion-image for ion: {ion} (centroided)\", fontsize = 14, loc = 'center')\n",
    "            ax2.set_title(f\"Total ion-image for ion: {ion} (non-centroided)\", fontsize = 14, loc = 'center')           \n",
    "        \n",
    "    else: # if not wanting to plot ion-images for uncentroided data\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize = (8, 8))\n",
    "        ax.imshow(total_image, interpolation='nearest',cmap = 'inferno', vmax = 0.6*np.max(total_image), vmin = 0, origin = 'lower')\n",
    "        ax.set_xlim(0,324)\n",
    "        ax.set_ylim(324,0) # Inverted to keep x,y directions the same as above\n",
    "        #ax.text(0.04, 0.89, ion, transform = ax.transAxes, fontsize = 15, color = 'white')\n",
    "        #ax.text(0.70,0.89, f\"{(Ti,Tf)}\", transform = ax.transAxes, fontsize = 15, color = 'white')\n",
    "        plt.ylabel('Pixels', fontsize=12, labelpad = 5)\n",
    "        plt.xlabel('Pixels', fontsize=12, labelpad = 5)\n",
    "        ax.grid(which='major')\n",
    "        ax.grid(which='minor', linewidth=0.3)\n",
    "        ax.minorticks_on()\n",
    "        \n",
    "        textstr = '\\n'.join((f\"TOF-domain: {(Ti,Tf)}\",f\"Assignment: {ion}\"))\n",
    "        props = dict(boxstyle='round', facecolor='white', alpha=0.7)\n",
    "        ax.text(0.05, 0.923, textstr, transform=ax.transAxes, fontsize=12, verticalalignment='center', bbox=props)\n",
    "    \n",
    "        \n",
    "        if crosshairs:\n",
    "            ax.axvline(162, c = 'w', ls = 'dashed', lw = 2, alpha = 0.75)\n",
    "            ax.axhline(162, c = 'w', ls = 'dashed', lw = 2, alpha = 0.75)\n",
    "            ax.add_patch(patches.Circle((162, 162), fill = False, color = 'white', ls = 'dashed', lw = 2))\n",
    "            ax.add_patch(plt.Circle([162,162], 70, edgecolor='w', facecolor='none')) # for plotting circle at centre\n",
    "            fig.savefig(f\"ion_image_{i}_crosshairs.png\")\n",
    "            \n",
    "        else:\n",
    "            fig.savefig(f\"ion_image_{i}_no_crosshairs.png\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 7. Obtain radial disributions of ions.\n",
    "\n",
    "pixels = 324\n",
    "rad_list_total = [] # for saving radial distributions as a list of lists\n",
    "\n",
    "for i, (Ti, Tf) in enumerate(ToF_list):\n",
    "    radius_for_dist = list(range(0, int(pixels/2)))\n",
    "    intensity_for_dist = [0]*int(pixels/2) # list of zeros for intensities\n",
    "    \n",
    "    ion = ion_list[i]\n",
    "    centre = centre_list[i]\n",
    "    image = list_of_total_images[i]\n",
    "    \n",
    "    for ii in list(range(np.shape(image)[0])):\n",
    "        for j in list(range(np.shape(image)[1])):\n",
    "            intensity = image[ii,j]\n",
    "            radius = int(np.sqrt((ii-162)**2+(j-162)**2))\n",
    "            #print(radius)\n",
    "            if 0 <= radius <= int(pixels/2):\n",
    "                intensity_for_dist[radius-1] += intensity\n",
    "            else:\n",
    "                pass\n",
    "    \n",
    "    rad_list_total.append(intensity_for_dist)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(15, 6))\n",
    "    beautify(ax)\n",
    "    plt.plot(radius_for_dist,intensity_for_dist,color='black')\n",
    "    ax.set_title('Radial distribution: ' + f\"{ion} {Ti,Tf}\", fontsize = 16)\n",
    "    plt.xlabel('Radius / pixels', fontsize=14)\n",
    "    plt.tick_params(axis='x', labelsize=12)\n",
    "    plt.ylabel('Intensity / a.u.', fontsize=14)\n",
    "    plt.tick_params(axis='y', labelsize=12)\n",
    "    ax.set_ylim(0,1.10*max(intensity_for_dist))\n",
    "    ax.grid(which='major')\n",
    "    ax.grid(which='minor', linewidth=0.3)\n",
    "    ax.minorticks_on()\n",
    "    plt.show()\n",
    "    #fig.savefig(f\"radial_distribution_{i}.png\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Compress data - not used (at this point in time) for real data.\n",
    "#    Adapted from: \"Recoil-frame covariance (for Part IIs, 220930).ipynb\"\n",
    "\n",
    "# Simulated data\n",
    "if file_type == 0:\n",
    "    compress_fac = 1 # this controls binning\n",
    "    compress_df = df.copy()\n",
    "    compress_df['x'] = (compress_df['x']/compress_fac).astype('int64')\n",
    "    compress_df['y'] = (compress_df['y']/compress_fac).astype('int64')\n",
    "    compress_centre_list = ((np.array(centre_list)/compress_fac).astype('int64'))\n",
    "    print(compress_df)\n",
    "    \n",
    "# Real data\n",
    "# if file_type == 1:\n",
    "    \n",
    "    #filtered_df_list = []\n",
    "    compress_fac = 1 # this controls binning\n",
    "    compress_centre_list = ((np.array(centre_list)/compress_fac).astype('int64'))\n",
    "    \n",
    "    #for df in zip(df_list):\n",
    "        #df=df[0]\n",
    "        #compress_df = df.filter(items=['x','y','ToF','tId']) # don't need delay column for static covariance analysis\n",
    "        #compress_df = compress_df.loc[(compress_df['ToF'] >= 1000) & (compress_df['ToF'] <= 1350)] # filter over total TOF range where signal seen\n",
    "        #filtered_df_list.append(compress_df)\n",
    "        \n",
    "    #compress_df = pd.concat(filtered_df_list)\n",
    "        \n",
    "#         compress_df = df.copy()\n",
    "#         compress_df['x'] = (compress_df['x']/compress_fac).astype('int64')\n",
    "#         compress_df['y'] = (compress_df['y']/compress_fac).astype('int64')\n",
    "#         compress_centre_list = ((np.array(centre_list)/compress_fac).astype('int64'))\n",
    "#         compress_df = df_total.copy()\n",
    "#     compress_df = df_total.copy()\n",
    "#     compress_df['x'] = (compress_df['x']/compress_fac).astype('int64')\n",
    "#     compress_df['y'] = (compress_df['y']/compress_fac).astype('int64')\n",
    "\n",
    "#     print(compress_df) # for total (summed over runs) concatenated dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 9. Calculating ion covariances, calling the main covariance function defined in (2). Have to do data-frame by data-frame.\n",
    "#    Adapted from: \"Recoil-frame covariance (for Part IIs, 220930).ipynb\"\n",
    "\n",
    "compress_fac = 1\n",
    "compress_centre_list = ((np.array(centre_list)/compress_fac).astype('int64'))\n",
    "\n",
    "pixels = int(324/compress_fac)\n",
    "#pixels = 162 # comment out if re-binning not needed\n",
    "term_list = []\n",
    "rad_term_list = []\n",
    "count = 1\n",
    "\n",
    "# fluorene 2023\n",
    "# pixels = 324\n",
    "# ToF_list = [(1613, 1616),(1617, 1621),(1631, 1634),(1643, 1646),(1650, 1652), (1657, 1662),(1662,1671),(1670, 1673), (1679,1683),(1688,1695),(1699,1705), (1708,1714), (1716,1723), (1725,1735),(1734,1741),(1743,1750), (1749,1755),(1756,1765),(1770,1776),(1783,1793), (1794,1803), (1810,1816),(1831,1841)]\n",
    "# ion_list = ['N(++)','O(++)','C2(++)','O(+)','water(+)','carbon_dioxide(++)','C2(+)','dinitrogen(+)','dioxygen(+)','C3(+)','carbon_dioxide(+)','C4(+)','PAH(+++)','C5(+)','C11(++)','C6(+)','PAH(++)','C7(+)','C8(+)','C9(+)','C10(+)','C11(+)','PAH-H(+)']\n",
    "# pq_list = [(2,2),(2,14),(14,2),(6,21),(21,6)] # just testing dication-dication atm\n",
    "#pq_list = [(2,21),(21,2)]\n",
    "# indices to consider (maximum = 22): 2,6,9,11,12,13,14,15,16,17,18,19,20,21\n",
    "\n",
    "# triphenylene 2021\n",
    "#ion_list = ['CH$^{2+}$','C$^{+}$','C$_{2}$H$_{2}^{+}$','C$_{3}$H$_{x}^{+}$','C$_{4}$H$_{x}^{+}$','C$_{5}$H$_{x}^{+}$','C$_{6}$H$_{x}^{+}$','C$_{7}$H$_{x}^{+}$','C$_{8}$H$_{x}^{+}$','C$_{9}$H$_{x}^{+}$']\n",
    "#ToF_list = [(1044,1046),(1061,1063),(1097,1099),(1119,1121),(1139,1141),(1156,1158),(1172,1174),(1187,1189),(1202,1204),(1216,1218)]\n",
    "#centre_list = [(165,162),(175,162),(178,162),(192,162),(195,162),(196,162),(198,162),(202,162),(205,162),(210,162)]\n",
    "\n",
    "# for fluorene 2018 data\n",
    "#pq_list = [(0,0),(0,1),(0,2),(0,3),(0,4),(0,5),(0,6),(0,7),(0,8),(0,9),(0,10),(1,1),(1,2),(1,3),(1,4),(1,5),(1,6),(1,7),(1,8),(1,9),(1,10),(2,2),(2,3),(2,4),(2,5),(2,6),(2,7),(2,8),(2,9),(2,10),(3,3),(3,4),(3,5),(3,6),(3,7),(3,8),(3,9),(3,10),(4,4),(4,5),(4,6),(4,7),(4,8),(4,9),(4,10),(5,5),(5,6),(5,7),(5,8),(5,9),(5,10),(6,6),(6,7),(6,8),(6,9),(6,10),(7,7),(7,8),(7,9),(7,10),(8,8),(8,9),(8,10),(9,9),(9,10),(10,10)] # this basically indexes the two ions in the ion list you want to calculate covariances for (where the first number is set as the reference ion)\n",
    "#pq_list = [(0,0),(0,1),(0,2),(0,3),(0,4),(0,5),(0,6),(0,7),(0,8),(0,9),(1,1),(1,2),(1,3),(1,4),(1,5),(1,6),(1,7),(1,8),(2,2),(2,3),(2,4),(2,5),(2,6),(2,7),(3,3),(3,4),(3,5),(3,6),(4,4),(4,5),(5,5),(6,6),(7,7),(8,8),(9,9),(10,10)]\n",
    "\n",
    "# for triphenylene 2021 data\n",
    "#pq_list = [(0,1),(0,2),(0,3),(0,4),(0,5),(0,6),(0,7),(0,8),(0,9),(1,2),(1,3),(1,4),(1,5),(1,6),(1,7),(1,8),(1,9),(2,3),(2,4),(2,5),(2,6),(2,7),(2,8),(2,9),(3,4),(3,5),(3,6),(3,7),(3,8),(3,9),(4,5),(4,6),(4,7),(4,8),(4,9),(5,6),(5,7),(5,8),(5,9),(6,7),(6,8),(6,9),(7,8),(7,9),(8,9)]\n",
    "\n",
    "# indene 2023\n",
    "#ToF_list = [(1630,1634),(1665,1670),(1685,1697),(1700,1703),(1708,1718),(1720,1722),(1725,1735),(1740,1750),(1755,1765),(1785,1795)]\n",
    "#ion_list = ['C1','C2','C3','C7(2+)','C4','IND(2+)','C5','C6','C7','IND(+)']\n",
    "#pq_list = [(0,1),(0,2),(0,3),(0,4),(0,6),(0,7),(0,8),(1,2),(1,3),(1,4),(1,6),(1,7),(1,8),(2,4),(2,6),(2,7),(4,6),(0,0),(1,1),(2,2),(4,4)]\n",
    "\n",
    "# fluorene 2023\n",
    "# ToF_list = [(1831,1840),(1820,1830),(1810,1818),(1798,1802),(1780,1792),(1770,1778),(1755,1765),(1750,1752),(1742,1749),(1735,1740),(1725,1733),(1720,1722),(1707,1715),(1699,1704),(1685,1698),(1662,1672),(1630,1633)]\n",
    "# ion_list = ['FLU(+)','C12(+)','C11(+)','C10(+)','C9(+)','C8(+)','C7(+)','FLU(++)','C6(+)','C11(++)','C5(+)','FLU(+++)/C9(++)','C4(+)','C3(+)','C7(++)/FLU(++++)','C2(+)','C1(+)']\n",
    "# pq_list = [(16,1),(16,2),(15,2),(16,3),(15,3),(13,3),(16,4),(15,4),(13,4),(12,4),(16,5),(15,5),(13,5),(12,5),(10,5),(16,6),(15,6),(13,6),(12,6),(10,6),(8,6),(16,9),(15,9),(16,11),(15,11),(13,11),(12,11),(16,14),(15,14),(13,14),(12,14),(10,14),(8,14),(16,8),(15,8),(13,8),(12,8),(10,8),(12,10),(13,10),(15,10),(16,10),(13,12),(15,12),(16,12),(15,13),(16,13),(15,16),(16,16),(15,15),(13,13),(12,12),(10,10),(8,8)]\n",
    "\n",
    "# CPP 2023\n",
    "# ToF_list = [(1631,1636),(1665,1671),(1686,1694),(1701,1707),(1710,1715),(1718,1722),(1725,1733),(1736,1740),(1742,1749),(1752,1754),(1757,1765),(1766,1770),(1772,1778),(1780,1791),(1795,1805),(1806,1815),(1820,1828),(1830,1838),(1842,1850),(1851,1860),(1864,1869)]\n",
    "# ion_list = ['C1','C2','C3','CPP(4+)','C4','C9(2+)','C5','C11(2+)','C6','C13(2+)','C7','CPP(2+)','C8','C9','C10','C11','C12','C13','C14','CPP(+)','[CPP-dinitrogen](+)']\n",
    "# pq_list = [(0,1),(0,2),(0,4),(0,5),(0,6),(0,7),(0,8),(0,9),(0,10),(0,12),(0,13),(0,14),(0,15),(0,16),(0,17),(0,18),(1,2),(1,4),(1,5),(1,6),(1,7),(1,8),(1,9),(1,10),(1,12),(1,13),(1,14),(1,15),(1,16),(1,17),(2,4),(2,5),(2,6),(2,7),(2,8),(2,10),(2,12),(2,13),(2,14),(2,15),(2,16),(4,5),(4,6),(4,7),(4,8),(4,10),(4,12),(4,13),(4,14),(4,15),(5,6),(5,8),(6,8),(6,10),(6,12),(6,13),(6,14),(8,10),(8,12),(8,13),(10,12)]\n",
    "#pq_list = [(4,7),(1,9),(8,5\n",
    "\n",
    "# ethene sim data\n",
    "ToF_list = [(7,7),(14,14)]\n",
    "ion_list = ['$CH_{2}^{++}$','$CH_{2}^{+}$']\n",
    "pq_list = [(0,0),(1,1),(0,1),(1,0)]\n",
    "df_list = [df]\n",
    "\n",
    "number_of_bins = 5 # for contingent covariance (in reality, number of bins is one minus from this value)\n",
    "\n",
    "# for df in zip(df_list): # looping over each run number to sort energy bin stuff out. Comment out energy lines if not wanting to do contingent covariance or if Energy isn't in the df\n",
    "        \n",
    "#     df = df[0].sort_values(by=['Energy']) # load dataframe in ascending energy value\n",
    "#     df_length = df.shape[0] # number of rows in total dataframe\n",
    "\n",
    "#     min_energy = df['Energy'].min()\n",
    "#     max_energy = df['Energy'].max()\n",
    "\n",
    "#     FEL_energy_bins = []\n",
    "\n",
    "#     index_range = np.arange(0, df_length, df_length/number_of_bins)\n",
    "#     index_range_int = []\n",
    "\n",
    "#     for a in range(len(index_range)): # need to make all values integers\n",
    "#         index_range_int.append(int(index_range[a]))\n",
    "\n",
    "#     print(f\"Integer index range: {index_range_int}\")\n",
    "\n",
    "#     for index in index_range_int:\n",
    "#         indexed_energy = df['Energy'].iloc[index]\n",
    "#         FEL_energy_bins.append(indexed_energy)\n",
    "\n",
    "#     print(f\"FEL energy bin values: {FEL_energy_bins}\")\n",
    "\n",
    "for (p, q) in pq_list: # looping over each specified ion pair\n",
    "    #     print(p,q)\n",
    "    print('Covariance %s of %s.' % (count, len(pq_list)))\n",
    "\n",
    "    (A_Ti, A_Tf), (B_Ti, B_Tf)  = ToF_list[p], ToF_list[q] # time windows for ion A and ion B, respectively\n",
    "    A_centre, B_centre = compress_centre_list[p], compress_centre_list[q] # for simulated data, both are centred at (162,162)\n",
    "\n",
    "        # ion A and ion B df filters\n",
    "    #     B_mask = (((compress_df['ToF']>= B_Ti) & (compress_df['ToF'] <= B_Tf)))\n",
    "    #     A_mask = (((compress_df['ToF']>= A_Ti) & (compress_df['ToF'] <= A_Tf)))\n",
    "    \n",
    "    Sij_store = []\n",
    "    SiSj_store = []\n",
    "    Sij_rad_store = []\n",
    "    SiSj_rad_store = []\n",
    "    \n",
    "    for df in zip(df_list): # looping over each run number\n",
    "        \n",
    "        df = df[0]\n",
    "        print(df)\n",
    "        \n",
    "        \n",
    "#         for i in range(len(FEL_energy_bins)- 1): # looping over each energy bin; each bin should have approx. same number of shots in them. This is for PRE-T0\n",
    "        \n",
    "#             FEL_lower = FEL_energy_bins[i]\n",
    "#             FEL_higher = FEL_energy_bins[i+1]\n",
    "\n",
    "#             FEL_filtered_df = df[(df['Energy'] >= FEL_lower) & (df['Energy'] <= FEL_higher)]\n",
    "#             #print(FEL_filtered_df)\n",
    "#             compress_df=FEL_filtered_df\n",
    "\n",
    "        FEL_filtered_df = df\n",
    "        compress_df = FEL_filtered_df\n",
    "        \n",
    "        print(compress_df)\n",
    "    \n",
    "        B_mask = (compress_df['ToF'].values >= B_Ti) & (compress_df['ToF'].values <= B_Tf)\n",
    "        A_mask = (compress_df['ToF'].values >= A_Ti) & (compress_df['ToF'].values <= A_Tf)\n",
    "\n",
    "        df_A = compress_df[A_mask].copy()\n",
    "        df_B = compress_df[B_mask].copy()\n",
    "\n",
    "        print(\"df_A\")\n",
    "        print(df_A) # dataframe with just ion A in them\n",
    "        print(\"df_B\")\n",
    "        print(df_B) # dataframe with just ion B in them\n",
    "\n",
    "        df_A['x'] -= A_centre[1] # just centres x values\n",
    "        df_A['y'] -= A_centre[0] # just centres y values\n",
    "        df_A['r'] = np.sqrt((df_A['x'])**2 + (df_A['y'])**2) # caluculates the radius for each ion hit \n",
    "        df_A['theta'] = np.arctan2(df_A['x'], df_A['y']) + np.pi\n",
    "\n",
    "        df_B['x'] -= B_centre[1] # just centres x values\n",
    "        df_B['y'] -= B_centre[0] # just centres y values\n",
    "        df_B['r'] = np.sqrt((df_B['x'])**2 + (df_B['y'])**2) # caluculates the radius for each ion hit \n",
    "        df_B['theta'] = np.arctan2(df_B['x'], df_B['y']) + np.pi\n",
    "\n",
    "        print(\"df_A new\")\n",
    "        print(df_A)\n",
    "        print(\"df_B new\")\n",
    "        print(df_B)\n",
    "\n",
    "        shot_list = np.arange(np.min(FEL_filtered_df.tId),np.max(FEL_filtered_df.tId) + 1) # just an array of shot IDs\n",
    "        #print(\"shot list\")\n",
    "        #print(shot_list)\n",
    "\n",
    "    #     print(df_A.dtypes, df_B.dtypes, shot_list.dtype)\n",
    "    #     print(df_B.dtypes)\n",
    "        Sij, SiSj, Sij_rad, SiSj_rad = two_fold_recoil_frame_covariance(df_A, df_B, shot_list, pixels, norm = True) # MAIN COVARIANCE FUNCTION\n",
    "        #count += 1\n",
    "        Sij_store.append(Sij)\n",
    "        SiSj_store.append(SiSj)\n",
    "        Sij_rad_store.append(Sij_rad)\n",
    "        SiSj_rad_store.append(SiSj_rad)\n",
    "        \n",
    "    # summing over each run number and energy bin\n",
    "    Sij = sum(Sij_store)\n",
    "    SiSj = sum(SiSj_store)\n",
    "    Sij_rad = sum(Sij_rad_store)\n",
    "    SiSj_rad = sum(SiSj_rad_store)\n",
    "    \n",
    "    term_list.append((Sij, SiSj))\n",
    "    rad_term_list.append((Sij_rad,SiSj_rad))\n",
    "    print('Finished covariance %s of %s.' % (count, len(pq_list)))\n",
    "    count += 1\n",
    "    #     break\n",
    "\n",
    "print('Finished.')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 10. Plotting the recoil-frame covariance maps.\n",
    "#     Adapted from: \"Recoil-frame covariance (for Part IIs, 220930).ipynb\"\n",
    "\n",
    "# fluorene 2018\n",
    "#pq_list = [(0,0),(0,1),(0,2),(0,3),(0,4),(0,5),(0,6),(0,7),(0,8),(0,9),(1,1),(1,2),(1,3),(1,4),(1,5),(1,6),(1,7),(1,8),(2,2),(2,3),(2,4),(2,5),(2,6),(2,7),(3,3),(3,4),(3,5),(3,6),(4,4),(4,5),(5,5),(6,6),(7,7),(8,8),(9,9),(10,10)]\n",
    "#print(pq_list)\n",
    "\n",
    "# triphenylene 2021\n",
    "#pq_list = [(0,1),(0,2),(0,3),(0,4),(0,5),(0,6),(0,7),(0,8),(0,9),(1,2),(1,3),(1,4),(1,5),(1,6),(1,7),(1,8),(1,9),(2,3),(2,4),(2,5),(2,6),(2,7),(2,8),(2,9),(3,4),(3,5),(3,6),(3,7),(3,8),(3,9),(4,5),(4,6),(4,7),(4,8),(4,9),(5,6),(5,7),(5,8),(5,9),(6,7),(6,8),(6,9),(7,8),(7,9),(8,9)]\n",
    "#print(pq_list)\n",
    "\n",
    "# fluorene 2023\n",
    "#ion_list = ['FLU(+)','C12(+)','C11(+)','C10(+)','C9(+)','C8(+)','C7(+)','FLU(++)','C6(+)','C11(++)','C5(+)','[FLU(+++)/C9(++)]','C4(+)','C3(+)','C7(++)','C2(+)','C1(+)']\n",
    "\n",
    "for i, (Sij, SiSj) in enumerate(term_list):\n",
    "    pq_tuple = pq_list[i]\n",
    "    # print(pq_tuple)\n",
    "    \n",
    "    # <XY>\n",
    "#     fig, ax = plt.subplots(figsize=(6, 6))\n",
    "#     maximage = Sij.max()\n",
    "#     picture = ax.imshow(Sij, interpolation='nearest', cmap='inferno', vmin=0, vmax=0.8*maximage)\n",
    "#     ax.set_title(str(ion_list[p]) + ' / ' + str(ion_list[q]) + ': <XY>')\n",
    "\n",
    "    # <X><Y>\n",
    "#     fig2, ax2 = plt.subplots(figsize=(6, 6))\n",
    "#     maximage2 = SiSj.max()\n",
    "#     picture = ax2.imshow(SiSj, interpolation='nearest', cmap='inferno', vmin=0, vmax=maximage2)\n",
    "#     ax2.set_title(str(ion_list[p]) + ' / ' + str(ion_list[q]) + ': <X><Y>')\n",
    "\n",
    "    # <XY>-<X><Y>\n",
    "    fig3, ax3 = plt.subplots(figsize=(8, 8)) # recoil-frame covariance plot - just one component of covariance\n",
    "    cov = Sij-SiSj\n",
    "    maximage3 = cov.max()\n",
    "    print(maximage3)\n",
    "    print(cov.min())\n",
    "    #print(maximage3)\n",
    "    if pq_tuple[0] != pq_tuple[1]: # if not looking at autocovariance\n",
    "        picture = ax3.imshow(Sij-SiSj, interpolation='nearest', cmap='inferno', vmin=0, vmax=maximage3)\n",
    "        plt.arrow(270,162,20,0, color='w',head_width=5)\n",
    "    elif pq_tuple[0] == pq_tuple[1]: # if looking at autocovariance (for image oversaturation to bring out covariance features against an overwhelming variance signal)\n",
    "        picture = ax3.imshow(Sij-SiSj, interpolation='nearest', cmap='inferno', vmin=0, vmax=maximage3)\n",
    "    ax3.set_title(str(ion_list[pq_tuple[0]]) + ' / ' + str(ion_list[pq_tuple[1]]) + ' recoil-frame covariance map (static)')\n",
    "    plt.xlabel('Pixels', fontsize = 12, labelpad = 5)\n",
    "    plt.ylabel('Pixels', fontsize = 12, labelpad = 5)\n",
    "    cbar = plt.colorbar(picture, shrink=0.82)\n",
    "    cbar.set_label('Covariance / a.u. ', rotation=270, fontsize = 12,labelpad=20)\n",
    "    plt.show()\n",
    "    \n",
    "    fig3.savefig(f\"{pq_tuple[0]}_{pq_tuple[1]}_recoil_frame_covariance_static.png\",bbox_inches=\"tight\")\n",
    "    #np.save(f\"{ion_list[pq_tuple[0]]}_{ion_list[pq_tuple[1]]}_covar_slice.npy\",cov) # save rf maps as np arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 13. Scaling the radial covariance matrices relative to the maximum matrix entry in a given matrix, and re-plotting. There is\n",
    "#     also an option to scale the matrices relative to one another. Re-bins into 81x81 maps, reinflates to 162x162, and plots.\n",
    "\n",
    "radcov_matrix_maxvals = []\n",
    "radcov_rebinned_list = []\n",
    "radcov_list = []\n",
    "\n",
    "for i, (Sij_rad, SiSj_rad) in enumerate(rad_term_list):\n",
    "    pq_tuple = pq_list[i]\n",
    "    #if pq_tuple[0] != pq_tuple[1]: # not looking at autocorrelation:\n",
    "    radcov = Sij_rad - SiSj_rad\n",
    "        \n",
    "    radcov_list.append(radcov)\n",
    "        \n",
    "        # re-binning into 81x81, then reinflating for plotting\n",
    "        #radcovmean = np.mean(np.split(np.mean(np.split(radcov, 162 // 2, axis=1), axis=-1), 162 // 2, axis=1), axis=-1) # for binning; 81 x 81 matrix\n",
    "        #radcov = np.kron(radcovmean, np.ones((2, 2))) # reinflates re-binned matrix for plotting\n",
    "        #radcov_rebinned_list.append(radcov)\n",
    "        \n",
    "    radcov_matrix_maxvals.append(np.max(radcov))\n",
    "        \n",
    "scaling_factor = max(radcov_matrix_maxvals) # maximum matrix entry across all radial covariance plots\n",
    "print(\"Scaling factor: \" + str(scaling_factor))\n",
    "radcov_matrix_maxvals_norm = radcov_matrix_maxvals/scaling_factor\n",
    "print(\"To check for correct normalisation (should equal 1): \" + str(max(radcov_matrix_maxvals_norm)))\n",
    "\n",
    "for i, radcov in enumerate(radcov_list):\n",
    "    \n",
    "    pq_tuple = pq_list[i]\n",
    "    \n",
    "    #if pq_tuple[0] != pq_tuple[1]: # not looking at autocorrelation:\n",
    "        \n",
    "        #radcov /= scaling_factor\n",
    "        \n",
    "    maximage = radcov.max()\n",
    "    print(maximage)\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "    gs = fig.add_gridspec(2, 2,  width_ratios=(3, 1), height_ratios=(1, 3),\n",
    "                          left=0.1, right=0.9, bottom=0.1, top=0.9,\n",
    "                          wspace=0, hspace=0)\n",
    "    ax = fig.add_subplot(gs[1, 0])\n",
    "\n",
    "    #ax.set_title(str(ion_list[pq_tuple[0]]) + '/' + str(ion_list[pq_tuple[1]]) + ': <XY> - <X><Y>', fontsize = 16)\n",
    "    ax.set_xlabel(str(ion_list[pq_tuple[1]]) + ' ion-image radius / pixels', fontsize=14, labelpad=15)    \n",
    "    ax.set_ylabel(str(ion_list[pq_tuple[0]]) + ' ion-image radius / pixels', fontsize=14, labelpad=15)\n",
    "    ax.grid(which='major')\n",
    "    ax.grid(which='minor', linewidth=0.3)\n",
    "    ax.minorticks_on()\n",
    "    ax_x = fig.add_subplot(gs[0, 0], sharex=ax) # radial dist (top row)\n",
    "    ax_y = fig.add_subplot(gs[1, 1], sharey=ax) # radial dist (column)\n",
    "    picture = ax.imshow(radcov, interpolation='nearest', cmap='inferno', vmin=0, vmax=0.5*maximage) # edit vmax as necessary\n",
    "\n",
    "    ax_x.plot(radius_for_dist, rad_list_total[pq_tuple[1]], color = 'purple')\n",
    "    ax_y.plot(rad_list_total[pq_tuple[0]], radius_for_dist, color = 'purple')\n",
    "    ax_x.set_ylabel('Intensity / a.u.', fontsize=14,labelpad=15)\n",
    "    ax_y.set_xlabel('Intensity / a.u.', fontsize=14,labelpad=15)\n",
    "    ax_x.tick_params(axis=\"x\",direction=\"out\", pad=5)\n",
    "    ax_y.tick_params(axis=\"y\",direction=\"out\", pad=5)\n",
    "    plt.setp(ax_x.get_xticklabels(), visible=False)\n",
    "    plt.setp(ax_y.get_yticklabels(), visible=False)\n",
    "    ax_x.grid(which='major')\n",
    "    ax_x.grid(which='minor', linewidth=0.3)\n",
    "    ax_x.minorticks_on()\n",
    "    ax_y.grid(which='major')\n",
    "    ax_y.grid(which='minor', linewidth=0.3)\n",
    "    ax_y.minorticks_on()\n",
    "\n",
    "    # colorbar formatting\n",
    "    fig.subplots_adjust(right=0.8)\n",
    "    cbar_ax = fig.add_axes([1, 0.15, 0.05, 0.7])\n",
    "    fig.colorbar(picture, cax=cbar_ax)\n",
    "    cbar_ax.set_ylabel('Covariance / a.u.', fontsize = 14, rotation = 270, labelpad=25)\n",
    "\n",
    "\n",
    "    ax_x.text(0.95, 0.82, str(ion_list[pq_tuple[1]]), horizontalalignment='right', verticalalignment='bottom', transform=ax_x.transAxes, fontsize = 14, weight='bold')\n",
    "    ax_y.text(0.90, 0.03, str(ion_list[pq_tuple[0]]), horizontalalignment='right', verticalalignment='bottom', transform=ax_y.transAxes, fontsize = 14, weight='bold')\n",
    "\n",
    "    fig.savefig(str(i) + '_radial_covariance_scaled.png',bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

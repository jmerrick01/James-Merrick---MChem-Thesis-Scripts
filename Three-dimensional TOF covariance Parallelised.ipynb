{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This script aims to calculate third cumulants (equal to three-fold covariances) between time-of-flight regions in real data.\n",
    "#   It is adapted with permission from James Somper's third cumulance codes for simulated data, and it is hoped that this\n",
    "#   adaptation for beamtime data may be useful for future beamtime analyses. It is intended that this code is run *after* radial\n",
    "#   covariance calculations are run and after the ToF spectrum has already been obtained analysed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Importing some useful modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "from numpy import exp, loadtxt, pi, sqrt\n",
    "import matplotlib.cm as cm\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from numba import njit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Reading in the data. Creates a list of dataframes. Takes in .npy files as input.\n",
    "\n",
    "pd.set_option('display.max_rows', 4096) # Controls number of lines displayed (PImMS maximum = 4096 timebins)\n",
    "\n",
    "directory=os.chdir(r\"/home/merrickj/Documents/indene_filtered_data_for_covariance\")\n",
    "#directory=os.chdir(r\"/home/merrickj/Documents/fluorene_filtered_data_for_covariance\")\n",
    "\n",
    "#file_list = ['038','039','040','041','042','043','044'] # run numbers for triphenylene, 2021\n",
    "file_list = ['indene_full_data_centroided_corrected']\n",
    "#file_list = ['fluorene_full_data_centroided_corrected']\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for f in zip(file_list):\n",
    "    print(f[0])\n",
    "    print('Opening file: '+f[0])\n",
    "    data = np.load(f\"{f[0]}.npy\", mmap_mode='r')\n",
    "    #df = pd.DataFrame(data, columns = ['Energy','tId','x','y','ToF','size','spread','delay','m_z'])\n",
    "    df = pd.DataFrame(data, columns = ['Energy','tId','x','y','ToF','size','spread','delay'])\n",
    "    df_list.append(df)\n",
    "    del data\n",
    "    gc.collect()\n",
    "    print(df)\n",
    "    \n",
    "# for just reading in 1% of the data for testing purposes\n",
    "#df = df.sort_values(by='tId')\n",
    "#df_list = np.array_split(df,100)\n",
    "#print(np.shape(df_list))\n",
    "#df = df_list[0]\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: PLotting ToF spectrum for (possible) ease of future plotting.\n",
    "\n",
    "# directory=os.chdir(r\"/home/merrickj/Documents/indene_ion_figs_and_cov_plots\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "plt.xlabel('Time-of-flight / a.u.', fontsize=12)\n",
    "plt.tick_params(axis='x', labelsize=12)\n",
    "plt.ylabel('Intensity / a.u.', fontsize=12)\n",
    "plt.tick_params(axis='y', labelsize=12)\n",
    "ax.set_xlim(1550,1800) # alter as necessary\n",
    "ax.grid(which='major')\n",
    "ax.grid(which='minor')\n",
    "ax.minorticks_on()\n",
    "tof_appended = []\n",
    "for df,file in zip(df_list,file_list):\n",
    "    plt.title('Run-concatenated ToF spectrum - indene', fontsize = 16)\n",
    "    df = df[(df['ToF']>1550) & (df['ToF']<1900)]\n",
    "    tof = df.groupby(['ToF']).size().reset_index(name='intensity')\n",
    "    tof_times_list = tof['ToF'].to_list()\n",
    "    #print(tof)\n",
    "    tof_appended.append(tof)\n",
    "    plt.plot(tof.ToF,tof.intensity,label=str(file))\n",
    "plt.show()\n",
    "# directory=os.chdir(r\"/home/merrickj/Documents/indene_ion_figs_and_cov_plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Adapting cumulant calculation function for real beamtime data. Note that three-fold covariance is given by:\n",
    "#         cov(A,B,C) = <abc>, where i = I - <i> (mean-scaled values)\n",
    "\n",
    "import numba\n",
    "from numba import jit\n",
    "from joblib import Parallel, delayed\n",
    "from numpy import random\n",
    "# Function for ease of plotting - will take in ToF list as an input. Will need to find midpoints of ToF tuples for plotting.\n",
    "\n",
    "def GeneratePlottableMassList3D(CountingArray1):\n",
    "    XArray = []\n",
    "    YArray = []\n",
    "    ZArray = []\n",
    "    for i in range(len(CountingArray1)):\n",
    "        for j in range(len(CountingArray1)):\n",
    "            for k in range(len(CountingArray1)):\n",
    "                XArray.append(CountingArray1[i])\n",
    "                YArray.append(CountingArray1[j])\n",
    "                ZArray.append(CountingArray1[k])\n",
    "    return XArray, YArray, ZArray\n",
    "\n",
    "# PlottingData is what is actually plotted\n",
    "\n",
    "def GenerateThirdCumulantPlottingData(list_of_lists):\n",
    "    \n",
    "    ### Loop to be parallelised\n",
    "    def run_i_loops(i):\n",
    "        print(i)\n",
    "        PlottingArray_i = []\n",
    "        CountingArray1 = list_of_lists[i]\n",
    "        #print(f\"Calculating set of cumulances {i} of {len(list_of_lists)}\")\n",
    "        for j in range(len(list_of_lists)):\n",
    "            CountingArray2 = list_of_lists[j]\n",
    "            for k in range(len(list_of_lists)):\n",
    "                CountingArray3 = list_of_lists[k]\n",
    "                #print(f\"Calculating third cumulant: {count}\")\n",
    "                PlottingArray_i.append((CalculateThirdCumulant(CountingArray1, CountingArray2, CountingArray3),i))\n",
    "        return (PlottingArray_i)\n",
    "    ###\n",
    "    ### Create list for each index in list_of_lists in the format (output_run_i_loops[i],i)\n",
    "    ### For the test data that returns an array of shape 10,100,2 \n",
    "    PlottingArray = Parallel(n_jobs=20, verbose=100)(delayed(run_i_loops)(i) for i in np.arange(len(list_of_lists)))\n",
    "\n",
    "    return PlottingArray\n",
    "# Calculates mean of an array\n",
    "\n",
    "def CalculateSingleExpectationValue(CountingArray):\n",
    "    ExpectationValue = np.sum(CountingArray)/len(CountingArray)\n",
    "    return ExpectationValue\n",
    "\n",
    "# Takes array of number of ions of a given type per shot and subtracts the mean number of ions of a given type per shot from each element in the array to get mean-scaled values\n",
    "\n",
    "def CreateMeanScaledArray(CountingArray1):\n",
    "    Expect1 = CalculateSingleExpectationValue(CountingArray1)\n",
    "    MeanScaledArray = CountingArray1 - Expect1\n",
    "    return MeanScaledArray\n",
    "\n",
    "# Function which actually calculates the third cumulant of three given ions. Takes three arrays as inputs.\n",
    "\n",
    "def CalculateThirdCumulant(CountingArray1, CountingArray2, CountingArray3):\n",
    "    if len(CountingArray1) != len(CountingArray2) or len(CountingArray1) != len(CountingArray2):\n",
    "        print(\"Cannot calculate third cumulant value due to insufficient data points in one array\")\n",
    "    else: \n",
    "        MeanScaled1 = CreateMeanScaledArray(CountingArray1)\n",
    "        MeanScaled2 = CreateMeanScaledArray(CountingArray2)\n",
    "        MeanScaled3 = CreateMeanScaledArray(CountingArray3)\n",
    "        ThirdCumulant = np.sum(np.multiply(MeanScaled1, np.multiply(MeanScaled2, MeanScaled3))) / len(MeanScaled1)\n",
    "        return ThirdCumulant\n",
    "\n",
    "# Plots the third cumulants on a three-dimensional plot\n",
    "\n",
    "def DisplayThirdCumulants(ToF_list_for_plotting):\n",
    "    PlottingXArray = GeneratePlottableMassList3D(ToF_list_for_plotting)[0]\n",
    "    #print(PlottingXArray)\n",
    "    PlottingYArray = GeneratePlottableMassList3D(ToF_list_for_plotting)[1]\n",
    "    #print(PlottingYArray)\n",
    "    PlottingZArray = GeneratePlottableMassList3D(ToF_list_for_plotting)[2]\n",
    "    #print(PlottingZArray)\n",
    "    MaxValue = np.max(PlottingArray)\n",
    "    \n",
    "    return PlottingXArray, PlottingYArray, PlottingZArray, MaxValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Step 5: Running the code! This is adapted with the possibility of contingent covariance, but this was found to severely reduce\n",
    "#         the signal-to-noise ratio. By setting number of bins to 2, covariance is calculated without contingency.\n",
    "\n",
    "# N.B.: Contingent covariance NOT implemented in this code.\n",
    "\n",
    "minToF = 1550\n",
    "maxToF = 1800\n",
    "points1 = np.arange(minToF-0.5, maxToF-0.5, 1).tolist()\n",
    "points2 = np.arange(minToF+0.5, maxToF+0.5, 1).tolist()\n",
    "ToF_list = list(zip(points1, points2)) \n",
    "print(f\"Length of ToF_list: {len(ToF_list)}\")\n",
    "\n",
    "#ion_list = ['C1','C2','C3','C7(2+)','C4','IND(2+)','C5','C6','C7','IND(+)']\n",
    "\n",
    "# Part (a): Getting data into a form in which it can be read directly into the functions above.\n",
    "\n",
    "data_store = [] # to store PlottingArray for each dataframe, which can then be summed element-wise later\n",
    "covar_contingent_store = [] # to store covariance maps for different FEL pulse energy intervals\n",
    "\n",
    "number_of_bins = 2 # (n.b: actual number of bins is this value minus 1)\n",
    "\n",
    "for df,file in zip(df_list,file_list):\n",
    "    \n",
    "    #print('Opening file: ' + file)\n",
    "    #count = 1\n",
    "    #df = df.to_numpy()\n",
    "    \n",
    "    #num_rows_total = np.shape(df)[0] # counts number of rows in numpy array of total data for iterating over later\n",
    "    #print(f\"Number of rows in total run number array: {num_rows_total}\")\n",
    "    #shot_array_total = np.unique(df[:,1]) # array of unique shot numbers in dataframe\n",
    "    #print(f\"Number of shots in total run number array: {len(shot_array_total)}\")\n",
    "    #FEL_bin_width = np.max(df[:,0])-np.min(df[:,0]) # this can be manually changed by the user, but make sure it's not too narrow to avoid a rubbish signal=to-noise ratio\n",
    "    #FEL_energy_bins = np.arange(np.min(df[:,0]), np.max(df[:,0])+FEL_bin_width ,FEL_bin_width)\n",
    "    #print(FEL_energy_bins)\n",
    "    \n",
    "    print(df)\n",
    "    df = df.to_numpy()\n",
    "    \n",
    "    list_of_ion_frequencies_per_shot = [] # array of lists; each list will be of number of ion occurences (for a given ion) per shot\n",
    "    ToF_list_for_plotting = [] # will be used to find midpoint of each tuple in ToF_list for plotting\n",
    "        \n",
    "    num_rows = np.shape(df)[0] # number of rows in new filtered df\n",
    "    shot_array = np.unique(df[:,1]) # array of unique shot numbers (tId) in dataframe\n",
    "\n",
    "    for i, (Ti, Tf) in enumerate(ToF_list): # considering each ion at a time\n",
    "\n",
    "        ion_count_per_shot_list = np.zeros(len(shot_array)) # initialising array\n",
    "\n",
    "        for row in range(num_rows): # iterating over rows in numpy data array\n",
    "\n",
    "            if Ti <= df[row, 4] <= Tf: # if time-of-flight of a given row falls in the ion ToF range:\n",
    "\n",
    "                shot_no = int(df[row,1]) # just extracts shot number\n",
    "                index = int(np.where(shot_array == shot_no)[0])\n",
    "                ion_count_per_shot_list[index] += 1\n",
    "\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "            \n",
    "        ion_count_per_shot_list = list(ion_count_per_shot_list) # turning into list format\n",
    "        list_of_ion_frequencies_per_shot.append(ion_count_per_shot_list) # list_of_ion_frequencies_per_shot becomes list of lists\n",
    "\n",
    "        if (i+1)%10 == 0: # just progress print statements\n",
    "            print(f\"Formatting for ToF range no. {i+1} of {len(ToF_list)} complete.\")\n",
    "            \n",
    "            \n",
    "    print(f\"*** Starting third cumulant calculations... ***\")\n",
    "    ### See comment in function for explanation of this output\n",
    "    PlottingArray = GenerateThirdCumulantPlottingData(list_of_ion_frequencies_per_shot) # PlottingArray is a list\n",
    "    #print(PlottingArray)\n",
    "    ### Concatenate above function into form (1000,2) (for test data), where each row in the array has a cumulant value, \n",
    "    ### and an i value that corresponds to the i value in list_of_lists[i] it is produced from\n",
    "    PlottingArray = np.concatenate(PlottingArray, axis =0)\n",
    "    \n",
    "    print(np.shape(PlottingArray))\n",
    "    print(np.shape(PlottingArray[0]))\n",
    "    print(PlottingArray[0])\n",
    "    \n",
    "    covar_contingent_store.append(PlottingArray) # covar_contingent_store become a list of lists for a given run number (refreshed after every run number)\n",
    "    \n",
    "    list_of_ion_frequencies_per_shot = [] # to clear for next iteration of FEL filters\n",
    "    \n",
    "    data_store.append([sum(x) for x in zip(*covar_contingent_store)]) # sum elements in list of lists elementwise\n",
    "    \n",
    "    print(f\"Finished three-fold covariance calculations for file: {file}\")\n",
    "    \n",
    "#print(np.shape(data_store))\n",
    "#PlottingArray = np.sum(data_store, axis=0) # for run-aggregated PlottingArray - not needed as just one run\n",
    "print(np.shape(PlottingArray))\n",
    "print(np.shape(PlottingArray[0]))\n",
    "print(PlottingArray[0])\n",
    "    \n",
    "print(\"Finished calculating all three-fold covariances.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Sorting out data into a way which can be plotted\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "# indene 2023\n",
    "ToF_list_reference = [(1630,1634),(1665,1670),(1685,1697),(1700,1703),(1708,1718),(1720,1722),(1725,1735),(1740,1750),(1755,1765),(1785,1795)]\n",
    "ion_list = ['C1','C2','C3','C7(2+)','C4','IND(2+)','C5','C6','C7','IND(+)']\n",
    "\n",
    "list_of_ToF_maps = [] # for all time intervals\n",
    "\n",
    "for i in range(len(ToF_list)):\n",
    "    filteredPlottingArray = [t for t in PlottingArray if int(t[1]) == i] # filter by i value\n",
    "    list_of_cumulants = np.array([j[0] for j in filteredPlottingArray]) # extract only first value (cumulant) in filtered list of tuples\n",
    "    matrix = list_of_cumulants.reshape((len(ToF_list),len(ToF_list))) # reshapes to plottable matrix\n",
    "    list_of_ToF_maps.append(matrix)\n",
    "    \n",
    "    if (i+1)%10 == 0: # just progress print statements\n",
    "        print(f\"Formatting covariance map for ToF range no. {i+1} of {len(ToF_list)} complete.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 7. Plotting!\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "tof_appended = []\n",
    "for df,file in zip(df_list,file_list):\n",
    "    print('Opening file: '+str(file[0]))\n",
    "    #df = df[(df['ToF']>1500) & (df['ToF']<1900)]\n",
    "    tof = df.groupby(['ToF']).size().reset_index(name='intensity')\n",
    "    tof_times_list = tof['ToF'].to_list()\n",
    "    tof_appended.append(tof)\n",
    "\n",
    "list_of_tof_intensities = []\n",
    "\n",
    "for tof_frame in zip(tof_appended):\n",
    "    tof_frame = tof_frame[0]\n",
    "    tof_intensity = tof_frame['intensity'].to_list()\n",
    "    list_of_tof_intensities.append(tof_intensity)\n",
    "\n",
    "total_summed_intensities = [sum(i) for i in zip(*list_of_tof_intensities)]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "plt.plot(tof_times_list,total_summed_intensities)\n",
    "\n",
    "ax.set_xlim(1550,1850)\n",
    "ax.grid(which='major')\n",
    "ax.grid(which='minor')\n",
    "ax.minorticks_on()\n",
    "plt.xlabel('Time-of-flight / arb. units', fontsize=16)\n",
    "plt.ylabel('Intensity / arb. units', fontsize=16)\n",
    "plt.title('Total ToF spectrum')\n",
    "#fig.savefig('triphenylene_total_tof.png')\n",
    "\n",
    "tof_times_list = [x-minToF for x in tof_times_list]\n",
    "\n",
    "for j, (Ti,Tf) in enumerate(ToF_list_reference):\n",
    "    toflist = points1\n",
    "    lower_index = toflist.index(Ti-0.5)\n",
    "    upper_index = toflist.index(Tf-0.5)\n",
    "    #print(lower_index, upper_index)\n",
    "    plotting_list = list_of_ToF_maps[lower_index:upper_index]\n",
    "    covar = sum(plotting_list)\n",
    "    \n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "    gs = fig.add_gridspec(2, 2,  width_ratios=(3, 1), height_ratios=(1, 3), left=0.1, right=0.9, bottom=0.1, top=0.9, wspace=0, hspace=0)\n",
    "    ax = fig.add_subplot(gs[1, 0])\n",
    "\n",
    "    ax_x = fig.add_subplot(gs[0, 0], sharex=ax) # TOF plot (top row)\n",
    "    ax_y = fig.add_subplot(gs[1, 1], sharey=ax) # TOF plot (column)\n",
    "\n",
    "    ax_x.plot(tof_times_list,total_summed_intensities, color = 'purple')\n",
    "    ax_y.plot(total_summed_intensities, tof_times_list, color = 'purple')\n",
    "\n",
    "    #ax.set_xlim(0,300)\n",
    "    ax_x.grid(which='major')\n",
    "    ax_x.grid(which='minor', linewidth=0.3)\n",
    "    ax_x.minorticks_on()\n",
    "    ax_y.grid(which='major')\n",
    "    ax_y.grid(which='minor', linewidth=0.3)\n",
    "    ax_y.minorticks_on()\n",
    "    ax_x.tick_params(axis=\"x\",direction=\"out\", pad=5)\n",
    "    ax_y.tick_params(axis=\"y\",direction=\"out\", pad=5)\n",
    "    ax.set_xlabel('Time-of-flight / a.u. ', fontsize=14,labelpad=15)\n",
    "    ax.set_ylabel('Time-of-flight / a.u. ', fontsize=14,labelpad=15)\n",
    "    ax_x.set_ylabel('Intensity / a.u. ', fontsize=14,labelpad=15)\n",
    "    ax_y.set_xlabel('Intensity / a.u. ', fontsize=14,labelpad=15)      \n",
    "    plt.setp(ax_x.get_xticklabels(), visible=False)\n",
    "    plt.setp(ax_y.get_yticklabels(), visible=False)\n",
    "\n",
    "    ax.grid(which='major')\n",
    "    ax.grid(which='minor', linewidth=0.3)\n",
    "    ax.minorticks_on()\n",
    "\n",
    "    picture = ax.imshow(covar, interpolation='nearest', cmap='inferno', vmin=0, vmax=np.max(covar)/20) # edit vmax as necessary\n",
    "\n",
    "    # colorbar formatting\n",
    "    fig.subplots_adjust(right=0.8)\n",
    "    #cbar_ax = fig.add_axes([1, 0.15, 0.05, 0.7])\n",
    "    \n",
    "    divider = make_axes_locatable(ax_y)\n",
    "    cax = divider.append_axes(\"right\", size=\"10%\", pad=0.10)\n",
    "\n",
    "    fig.colorbar(picture, cax=cax, pad = 0.1)\n",
    "    cax.set_ylabel('Covariance / a.u.', fontsize = 14, rotation = 270, labelpad=25)\n",
    "    \n",
    "    ax_x.text(0.50, 1.10, f\"3D TOF-TOF covariance plot (reference ion: {ion_list[j]})\", horizontalalignment='center', verticalalignment='center', transform=ax_x.transAxes, fontsize = 14, weight='bold')\n",
    "\n",
    "    shw = ax.imshow(covar, cmap='inferno', origin='lower',vmin=0, vmax=np.max(covar)/10)\n",
    "    \n",
    "    directory=os.chdir(r\"/home/merrickj/Documents/indene_ion_figs_and_cov_plots\")\n",
    "    fig.savefig(f\"TOF_3D_covariance_indene_ref_{j}\",bbox_inches=\"tight\")\n",
    "\n",
    "    #directory=os.chdir(r\"/home/merrickj/Documents/fluorene_ion_figs_and_cov_plots\")\n",
    "    #fig.savefig(f\"TOF_3D_covariance_fluorene_ref_{j}\",bbox_inches=\"tight\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Step 8: Test to see if event-rate (ions per shot) is Poisson-distributed to confirm reliability of using third \n",
    "#         cumulance. Makes sense to plot run-separated event-rate distributions for each shot since third cumulant code is\n",
    "#         run on each run number in turn and not on a concatenated dataset.\n",
    "    \n",
    "for df,file in zip(df_list,file_list):\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(15, 6))\n",
    "\n",
    "    plt.xlabel('Ions per shot', fontsize=16)\n",
    "    plt.tick_params(axis='x', labelsize=12)\n",
    "    plt.ylabel('Frequency', fontsize=16)\n",
    "    plt.tick_params(axis='y', labelsize=12)\n",
    "    ax.grid(which='major')\n",
    "    ax.grid(which='minor')\n",
    "    ax.minorticks_on()\n",
    "    \n",
    "    plt.title(f\"Run-separated event-rate distribution for file: {file}\")\n",
    "    event_rate = df.groupby(['tId']).size().reset_index(name='frequency')\n",
    "    ions_in_shot = np.array(event_rate['frequency'])\n",
    "    ax.hist(ions_in_shot, bins = 80)\n",
    "    plt.show()\n",
    "    \n",
    "    mu_event = int(np.mean(ions_in_shot))\n",
    "    print(f\"Mean calculated for file {file}: {mu_event}\")\n",
    "    std_event= int(np.std(ions_in_shot))\n",
    "    print(f\"Standard deviation calculated for file {file}: {std_event}\")\n",
    "    \n",
    "    fig.savefig(f\"TOF_3D_test_if_poisson_indene_ref_{j}\",bbox_inches=\"tight\")\n",
    "    #fig.savefig(f\"TOF_3D_test_if_poisson_CPP_ref_{j}\",bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Step 5: Running the code! This is adapted with the possibility of contingent covariance, but this was found to severely reduce\n",
    "#         the signal-to-noise ratio. By setting number of bins to 2, covariance is calculated without contingency. ***WIP\n",
    "\n",
    "# N.B.: Contingent covariance NOT implemented in this code.\n",
    "\n",
    "minToF = 1550\n",
    "maxToF = 1800\n",
    "points1 = np.arange(minToF-0.5, maxToF-0.5, 1).tolist()\n",
    "points2 = np.arange(minToF+0.5, maxToF+0.5, 1).tolist()\n",
    "ToF_list = list(zip(points1, points2)) \n",
    "print(f\"Length of ToF_list: {len(ToF_list)}\")\n",
    "\n",
    "ion_list = ['C1','C2','C3','C7(2+)','C4','IND(2+)','C5','C6','C7','IND(+)']\n",
    "\n",
    "# Part (a): Getting data into a form in which it can be read directly into the functions above.\n",
    "\n",
    "covar_contingent_store = [] # to store covariance maps for different FEL pulse energy intervals\n",
    "\n",
    "number_of_bins = 5 # for contingent covariance (in reality, number of bins is one minus from this value) (JHM)\n",
    "\n",
    "for df in zip(df_list): # looping over each run number to sort energy bin stuff out\n",
    "        \n",
    "    df = df[0].sort_values(by=['Energy']) # load dataframe in ascending energy value\n",
    "    df_length = df.shape[0] # number of rows in total dataframe\n",
    "\n",
    "    min_energy = df['Energy'].min()\n",
    "    max_energy = df['Energy'].max()\n",
    "\n",
    "    FEL_energy_bins = []\n",
    "\n",
    "    index_range = np.arange(0, df_length, df_length/number_of_bins)\n",
    "    index_range_int = []\n",
    "\n",
    "    for a in range(len(index_range)): # need to make all values integers\n",
    "        index_range_int.append(int(index_range[a]))\n",
    "\n",
    "    print(f\"Integer index range: {index_range_int}\")\n",
    "\n",
    "    for index in index_range_int:\n",
    "        indexed_energy = df['Energy'].iloc[index]\n",
    "        FEL_energy_bins.append(indexed_energy)\n",
    "\n",
    "    print(f\"FEL energy bin values: {FEL_energy_bins}\")\n",
    "\n",
    "for df,file in zip(df_list,file_list):\n",
    "    \n",
    "    #print('Opening file: ' + file)\n",
    "    #count = 1\n",
    "    #df = df.to_numpy()\n",
    "    \n",
    "    #num_rows_total = np.shape(df)[0] # counts number of rows in numpy array of total data for iterating over later\n",
    "    #print(f\"Number of rows in total run number array: {num_rows_total}\")\n",
    "    #shot_array_total = np.unique(df[:,1]) # array of unique shot numbers in dataframe\n",
    "    #print(f\"Number of shots in total run number array: {len(shot_array_total)}\")\n",
    "    #FEL_bin_width = np.max(df[:,0])-np.min(df[:,0]) # this can be manually changed by the user, but make sure it's not too narrow to avoid a rubbish signal=to-noise ratio\n",
    "    #FEL_energy_bins = np.arange(np.min(df[:,0]), np.max(df[:,0])+FEL_bin_width ,FEL_bin_width)\n",
    "    #print(FEL_energy_bins)\n",
    "    \n",
    "    print(df)\n",
    "    \n",
    "    for j in range(len(FEL_energy_bins)- 1): # iterating over each energy bin filtered data\n",
    "        \n",
    "        print(f\"*** Contingent covariance bin {j+1} of {len(FEL_energy_bins)}: ***\")\n",
    "        \n",
    "        FEL_lower = FEL_energy_bins[j]\n",
    "        FEL_higher = FEL_energy_bins[j+1]\n",
    "        \n",
    "        FEL_filtered_df = df[(df['Energy'] >= FEL_lower) & (df['Energy'] <= FEL_higher)]\n",
    "        \n",
    "        FEL_filtered_df = FEL_filtered_df.to_numpy()\n",
    "    \n",
    "        list_of_ion_frequencies_per_shot = [] # array of lists; each list will be of number of ion occurences (for a given ion) per shot\n",
    "        ToF_list_for_plotting = [] # will be used to find midpoint of each tuple in ToF_list for plotting\n",
    "\n",
    "        num_rows = np.shape(FEL_filtered_df)[0] # number of rows in new filtered df\n",
    "        shot_array = np.unique(FEL_filtered_df[:,1]) # array of unique shot numbers (tId) in dataframe\n",
    "\n",
    "        for i, (Ti, Tf) in enumerate(ToF_list): # considering each ion at a time\n",
    "\n",
    "            ion_count_per_shot_list = np.zeros(len(shot_array)) # initialising array\n",
    "\n",
    "            for row in range(num_rows): # iterating over rows in numpy data array\n",
    "\n",
    "                if Ti <= FEL_filtered_df[row, 4] <= Tf: # if time-of-flight of a given row falls in the ion ToF range:\n",
    "\n",
    "                    shot_no = int(FEL_filtered_df[row,1]) # just extracts shot number\n",
    "                    index = int(np.where(shot_array == shot_no)[0])\n",
    "                    ion_count_per_shot_list[index] += 1\n",
    "\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "\n",
    "            ion_count_per_shot_list = list(ion_count_per_shot_list) # turning into list format\n",
    "            list_of_ion_frequencies_per_shot.append(ion_count_per_shot_list) # list_of_ion_frequencies_per_shot becomes list of lists\n",
    "\n",
    "            if (i+1)%10 == 0: # just progress print statements\n",
    "                print(f\"Formatting for ToF range no. {i+1} of {len(ToF_list)} complete.\")\n",
    "\n",
    "\n",
    "        print(f\"*** Starting third cumulant calculations... ***\")\n",
    "        ### See comment in function for explanation of this output\n",
    "        PlottingArray = GenerateThirdCumulantPlottingData(list_of_ion_frequencies_per_shot) # PlottingArray is a list\n",
    "        #print(PlottingArray)\n",
    "        ### Concatenate above function into form (1000,2) (for test data), where each row in the array has a cumulant value, \n",
    "        ### and an i value that corresponds to the i value in list_of_lists[i] it is produced from\n",
    "        PlottingArray = np.concatenate(PlottingArray, axis =0)\n",
    "\n",
    "        print(np.shape(PlottingArray))\n",
    "        print(np.shape(PlottingArray[0]))\n",
    "        print(PlottingArray[0])\n",
    "\n",
    "        covar_contingent_store.append(PlottingArray) # covar_contingent_store become a list of lists for a given run number (refreshed after every run number)\n",
    "\n",
    "        list_of_ion_frequencies_per_shot = [] # to clear for next iteration of FEL filters\n",
    "    \n",
    "    print(f\"Finished three-fold covariance calculations for file: {file}\")\n",
    "    \n",
    "#print(np.shape(data_store))\n",
    "#PlottingArray = np.sum(data_store, axis=0) # for run-aggregated PlottingArray - not needed as just one run\n",
    "print(np.shape(PlottingArray))\n",
    "print(np.shape(PlottingArray[0]))\n",
    "print(PlottingArray[0])\n",
    "    \n",
    "print(\"Finished calculating all three-fold covariances! :)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Sorting out data into a way which can be plotted.\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "# indene 2023\n",
    "ToF_list_reference = [(1630,1634),(1665,1670),(1685,1697),(1700,1703),(1708,1718),(1720,1722),(1725,1735),(1740,1750),(1755,1765),(1785,1795)]\n",
    "ion_list = ['C1','C2','C3','C7(2+)','C4','IND(2+)','C5','C6','C7','IND(+)']\n",
    "\n",
    "# fluorene 2023\n",
    "#ToF_list_reference = [(1831,1840),(1820,1830),(1810,1818),(1798,1802),(1780,1792),(1770,1778),(1755,1765),(1750,1752),(1742,1749),(1735,1740),(1725,1733),(1720,1722),(1707,1715),(1699,1704),(1685,1698),(1662,1672),(1630,1633)]\n",
    "#ion_list = ['FLU(+)','C12(+)','C11(+)','C10(+)','C9(+)','C8(+)','C7(+)','FLU(++)','C6(+)','C11(++)','C5(+)','FLU(+++)/C9(++)','C4(+)','C3(+)','C7(++)/FLU(++++)','C2(+)','C1(+)']\n",
    "\n",
    "list_of_ToF_maps = [] # for all time intervals\n",
    "\n",
    "for i in range(len(ToF_list)): # for each time interval for ALL time bins\n",
    "    \n",
    "    matrix_store = [] # for storing maps for a given time bin from different energy bins (from contingent)\n",
    "    \n",
    "    for PlottingArray in covar_contingent_store:\n",
    "        \n",
    "        filteredPlottingArray = [t for t in PlottingArray if int(t[1]) == i] # filter PlottingArray by i value\n",
    "        list_of_cumulants = np.array([j[0] for j in filteredPlottingArray]) # extract only first value (cumulant) in filtered list of tuples\n",
    "        matrix = list_of_cumulants.reshape((len(ToF_list),len(ToF_list))) # reshapes to plottable matrix\n",
    "        matrix_store.append(matrix)\n",
    "        \n",
    "    matrix = sum(matrix_store)\n",
    "    list_of_ToF_maps.append(matrix)\n",
    "    \n",
    "    if (i+1)%10 == 0: # just progress print statements\n",
    "        print(f\"Formatting covariance map for ToF range no. {i+1} of {len(ToF_list)} complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
